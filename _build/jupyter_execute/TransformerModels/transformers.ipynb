{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jUhmjau2BdND"
   },
   "source": [
    "## Transformers로 뭘 할 수 있을까요?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "peAEoQyQBwUQ"
   },
   "source": [
    "Transformers와 Datasets 라이브러리를 설치해줍니다 (-q 옵션은 로그를 생략하기 위해 사용했습니다)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ot-FUuVSBDGj"
   },
   "outputs": [],
   "source": [
    "!pip install transformers[sentencepiece] datasets -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xpZi4XsZCFJt"
   },
   "source": [
    "pipeline api는 inference 과정을 위해 전처리등 여러가지 과정을 압축한 high-level api입니다. 아래와 같이 사용할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8um4Sp3XBFVr",
    "outputId": "104be729-1e15-4d65-8be8-0dcd9455c7a2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9598048329353333}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"sentiment-analysis\")\n",
    "classifier(\"I've been waiting for a HuggingFace course my whole life.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2AorxM4zB9El"
   },
   "source": [
    "리스트형 입력을 사용하면 한문장뿐만 아니라 여러문장도 처리할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i-PPYtEuBLxz",
    "outputId": "0f119c62-eaa1-4c65-9bd9-1320d8fa489f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9598048329353333},\n",
       " {'label': 'NEGATIVE', 'score': 0.9994558691978455}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\n",
    "    [\"I've been waiting for a HuggingFace course my whole life.\", \"I hate this so much!\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GHX_t5QhEP_N"
   },
   "source": [
    "이 파이프라인은 프리트레이닝된 모델을 감성분석 데이터셋에 파인튜닝한 모델을 사용했습니다. 모델은 classifier 객체를 생성할때 다운로드 및 캐싱되게 됩니다. 그러므로 다음번 객체를 생성할땐 추가로 다운받지 않아도 됩니다.\n",
    "\n",
    "pipeline에 텍스트를 입력으로 넣게되면 다음과 같이 크게 3가지 과정을 거치게 됩니다.\n",
    "\n",
    "1. 텍스트가 모델이 이해할 수 있는 포멧으로 전처리 됩니다\n",
    "2. 전처리된 값이 모델에 입력됩니다.\n",
    "3. 모델의 예측값이 인간이 이해할 수 있는 형태로 후처리됩니다.\n",
    "\n",
    "\n",
    "사용 가능한 형태의 pipeline은 [아래](https://huggingface.co/docs/transformers/main_classes/pipelines)와 같이 여러 종류로 이루어져있습니다.\n",
    "\n",
    "- feature-extraction (get the vector representation of a text)\n",
    "- fill-mask\n",
    "- ner (named entity recognition)\n",
    "- question-answering\n",
    "- sentiment-analysis\n",
    "- summarization\n",
    "- text-generation\n",
    "- translation\n",
    "- zero-shot-classification\n",
    "\n",
    "이제부터 각 pipeline을 한번 살펴보겠습니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uv5OkIswbtJ5"
   },
   "source": [
    "## Zero-shot classification\n",
    "조금은 도전적인 태스크부터 다뤄보겠습니다. 보통의 텍스트 분류 문제는 레이블 데이터를 모으고, 분류기를 학습해서 문제를 해결합니다. 하지만 이는 시간이 드는 문제고, 도메인 전문가의 도움이 필요할 수도 있습니다. 이러한 경우 `zero-shot-classification` pipeline은 매우 유용하게 쓰일 수 있습니다. zero-shot은 학습을 않고 바로 분류하는 경우를 말하는데요. 분류할 문장과 다양한 클래스를 모델에 입력으로 넣어주면, 문장과 클래스의 연관도를 확률로 출력해줍니다. 내부적으로는 `MNLI`데이터셋으로 파인튜닝된 모델을 사용합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "on6SLjXIB55U",
    "outputId": "4701fc9e-e773-4e05-81e3-d49d483a8638"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'labels': ['education', 'business', 'politics'],\n",
       " 'scores': [0.8445989489555359, 0.11197411268949509, 0.04342697188258171],\n",
       " 'sequence': 'This is a course about the Transformers library'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"zero-shot-classification\")\n",
    "classifier(\n",
    "    \"This is a course about the Transformers library\",\n",
    "    candidate_labels=[\"education\", \"politics\", \"business\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lE_JYcRHUfwi"
   },
   "source": [
    "위와 같이 분류하고자하는 도메인 데이터에 대해서 파인튜닝할 필요가 없기 때문에 *zero-shot* 이라고 부릅니다\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XNBRaR8uU0gX"
   },
   "source": [
    "## Text generation\n",
    "지금부터는 텍스트 생성을 위한 pipleline을 살펴보겠습니다. 텍스트 생성을 위한 메인 아이디어는 프롬프트(prompt; 생성될 문장 앞에 들어가는 텍스트)를 제공하는 것입니다. 프롬프트가 입력되면 모델은 남은 영역을 문장 생성을 통해 완성시키게됩니다.   \n",
    "텍스트 생성은 기본적으로 랜덤 속성이 있기 때문에 아래와 같은 문장이 생성되지 않더라도 정상입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "akY_yOjrEKPI",
    "outputId": "a7e467ec-04b0-4a6d-9dd4-2f8d918f38e9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to gpt2 (https://huggingface.co/gpt2)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': \"In this course, we will teach you how to construct a user-friendly app using your existing browser experience. We'll also create custom content and design\"},\n",
       " {'generated_text': 'In this course, we will teach you how to use the Mapper to learn more. We will have a look at some more basics of Mapper'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "generator = pipeline(\"text-generation\")\n",
    "generator(\"In this course, we will teach you how to\",\n",
    "          max_length=30,\n",
    "          num_return_sequences=2,\n",
    "          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kIpCcxFGWAcO"
   },
   "source": [
    "`num_return_sequences`와 `max_length` 옵션을 통해 생성할 문장 개수 및 문장 길이를 조절할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s53oa9fzHcGt"
   },
   "source": [
    "## Model Hub에 있는 모델로 pipeline 만들기\n",
    "위에서 나온 예제외에 다른 모델을 사용해보고 싶다면 허깅페이스의 Model hub (https://huggingface.co/models)에 있는 다른 모델을 이용해볼 수 있습니다.\n",
    "다른 text-generation 모델은 [이곳](https://huggingface.co/models?pipeline_tag=text-generation)에서 확인할 수 있습니다. \n",
    "\n",
    "\n",
    "이번에는 [distilgpt2](https://huggingface.co/distilgpt2) 모델을 사용해보겠습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8UyV9_pOVu9J",
    "outputId": "7561e6d3-909c-435d-e17c-0313e746ed33"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'In this course, we will teach you how to best follow the rules of the Bitcoin Blockchain.'},\n",
       " {'generated_text': \"In this course, we will teach you how to perform these basic rules to prepare for an amazing experience. We don't have the usual rules to prepare\"}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "generator = pipeline(\"text-generation\", model=\"distilgpt2\")\n",
    "generator(\n",
    "    \"In this course, we will teach you how to\",\n",
    "    max_length=30,\n",
    "    num_return_sequences=2,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_nxUFth9J15l"
   },
   "source": [
    "[모델 허브](https://huggingface.co/models)에서 필터를 사용하면, 원하는 Tasks와 Languages에 맞는 모델을 찾을 수 있습니다. (한국어는 `ko` 태그를 통해 찾을 수 있습니다)\n",
    "\n",
    "![model_filter](https://user-images.githubusercontent.com/7252598/145123053-ffea71a8-a22e-4c17-b4f0-3f28fb6b4be0.gif)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AJtOMtZ2NtA3"
   },
   "source": [
    "## Inference API\n",
    "모든 모델은 허깅페이스에서 제공하는 Inference API를 통해 웹브라우저에서 테스트해볼 수 있습니다.\n",
    "\n",
    "![inference api](https://user-images.githubusercontent.com/7252598/145122531-3e523309-e038-4bdd-8e18-4d48174b6fe6.gif)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pWngMg8FnJ_S"
   },
   "source": [
    "## Mask filling\n",
    "이번에 소개할 파이프라인은 `fill-mask`입니다. 쉽게말하면 빈칸 채우기 task입니다. 빈칸이 있는 텍스트가 주어졌을때 확률적으로 가장 적절한 단어를 채워줍니다. 빈칸은 특수 토큰인 `<mask>`로 표기하고, `top_k` 인자는 확률이 높은 단어를 몇개까지 출력할지를 결정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_hLEdNusHZoq",
    "outputId": "1b5710d9-6dd5-45c3-8263-80127c05ef68"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilroberta-base (https://huggingface.co/distilroberta-base)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'score': 0.196198508143425,\n",
       "  'sequence': 'This course will teach you all about mathematical models.',\n",
       "  'token': 30412,\n",
       "  'token_str': ' mathematical'},\n",
       " {'score': 0.040527332574129105,\n",
       "  'sequence': 'This course will teach you all about computational models.',\n",
       "  'token': 38163,\n",
       "  'token_str': ' computational'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "unmasker = pipeline(\"fill-mask\")\n",
    "unmasker(\"This course will teach you all about <mask> models.\", top_k=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FowrubbKAsCE"
   },
   "source": [
    "## Named entity recognition\n",
    "개체명인식은 입력 텍스트에서 person(PER), location(LOC), organization(ORG)등에 대응되는 부분(토큰)을 찾아내는 태스크입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Mb0bArgKnfK9",
    "outputId": "d116947d-531d-4dfc-a7df-b005b1291d8d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english)\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/pipelines/token_classification.py:129: UserWarning: `grouped_entities` is deprecated and will be removed in version v5.0.0, defaulted to `aggregation_strategy=\"AggregationStrategy.SIMPLE\"` instead.\n",
      "  f'`grouped_entities` is deprecated and will be removed in version v5.0.0, defaulted to `aggregation_strategy=\"{aggregation_strategy}\"` instead.'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'end': 18,\n",
       "  'entity_group': 'PER',\n",
       "  'score': 0.9981694,\n",
       "  'start': 11,\n",
       "  'word': 'Sylvain'},\n",
       " {'end': 45,\n",
       "  'entity_group': 'ORG',\n",
       "  'score': 0.97960186,\n",
       "  'start': 33,\n",
       "  'word': 'Hugging Face'},\n",
       " {'end': 57,\n",
       "  'entity_group': 'LOC',\n",
       "  'score': 0.99321055,\n",
       "  'start': 49,\n",
       "  'word': 'Brooklyn'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "ner = pipeline(\"ner\", grouped_entities=True)\n",
    "ner(\"My name is Sylvain and I work at Hugging Face in Brooklyn.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I4Z-f-PGCcb_"
   },
   "source": [
    "transformer 계열의 모델은 입력형태가 서브워드형태로 이루어지기 때문에 실제 엔티티는 서브워드토큰 마다 태깅되게 됩니다. `grouped_entities=True` 조건은 이러한 서브워드들을 하나의 단어 형태로 변환해줍니다.\n",
    "`grouped_entities=False`로 할 경우 `Hugging Face`-> `Hu ##gging Face` 각각에 `ORG` 클래스가 태깅되게 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P4uxHq-PDayM"
   },
   "source": [
    "## Question answering\n",
    "question answering은 질문과 컨텍스트를 입력으로 넣었을때, 컨텍스트내에서 질문의 답과 가장 연관이 많은 부분을 `extractive`하게 추출하는 태스크입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M8m59T89CF9J",
    "outputId": "82f6932e-32c2-4632-d8a8-b26605c1247d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-cased-distilled-squad (https://huggingface.co/distilbert-base-cased-distilled-squad)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'answer': 'Hugging Face', 'end': 45, 'score': 0.6949771046638489, 'start': 33}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "question_answerer = pipeline(\"question-answering\")\n",
    "question_answerer(\n",
    "    question=\"Where do I work?\",\n",
    "    context=\"My name is Sylvain and I work at Hugging Face in Brooklyn\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8AUU70wLG6q7"
   },
   "source": [
    "## Summarization\n",
    "요약은 주어진 본문중 중요한 부분 위주로 글을 간추리는 태스크입니다. 텍스트 생성과 같이 `max_length`, `min_length` 인자로 글의 양을 조절할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yDe5H0jxG8In",
    "outputId": "eee04a71-7863-4715-f3f2-9c5c294eaa5a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 (https://huggingface.co/sshleifer/distilbart-cnn-12-6)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'summary_text': ' America has changed dramatically during recent years . The number of engineering graduates in the U.S. has declined in traditional engineering disciplines such as mechanical, civil,    electrical, chemical, and aeronautical engineering . Rapidly developing economies such as China and India continue to encourage and advance the teaching of engineering .'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "summarizer = pipeline(\"summarization\")\n",
    "summarizer(\n",
    "    \"\"\"\n",
    "    America has changed dramatically during recent years. Not only has the number of \n",
    "    graduates in traditional engineering disciplines such as mechanical, civil, \n",
    "    electrical, chemical, and aeronautical engineering declined, but in most of \n",
    "    the premier American universities engineering curricula now concentrate on \n",
    "    and encourage largely the study of engineering science. As a result, there \n",
    "    are declining offerings in engineering subjects dealing with infrastructure, \n",
    "    the environment, and related issues, and greater concentration on high \n",
    "    technology subjects, largely supporting increasingly complex scientific \n",
    "    developments. While the latter is important, it should not be at the expense \n",
    "    of more traditional engineering.\n",
    "\n",
    "    Rapidly developing economies such as China and India, as well as other \n",
    "    industrial countries in Europe and Asia, continue to encourage and advance \n",
    "    the teaching of engineering. Both China and India, respectively, graduate \n",
    "    six and eight times as many traditional engineers as does the United States. \n",
    "    Other industrial countries at minimum maintain their output, while America \n",
    "    suffers an increasingly serious decline in the number of engineering graduates \n",
    "    and a lack of well-educated engineers.\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GySAGGA2G-lv"
   },
   "source": [
    "## Translation\n",
    "간단하게 번역할 수 있는 파이프라인도 제공됩니다. model hub에서 번역할 언어쌍이 명시된 모델([Helsinki-NLP/opus-mt-ko-en](https://huggingface.co/Helsinki-NLP/opus-mt-ko-en))을 선택해서 사용할 수 있습니다. 텍스트 생성과 같이 `max_length`, `min_length` 인자로 글의 양을 조절할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I1EHd2VqG9q3",
    "outputId": "b9c42800-4ba4-4696-8aea-f605ac5d1261"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'translation_text': 'The NLP that you learn with Huggingface is great.'}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "translator = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-ko-en\")\n",
    "translator(\"Huggingface로 배우는 NLP는 멋져\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "2Ff4JQ5tHzIW"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "transformers.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}