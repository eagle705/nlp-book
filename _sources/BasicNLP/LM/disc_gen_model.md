# Discriminative VS Generative model

Discriminative model과 Generative model은 둘 다 머신 러닝에서 자주 사용되는 용어입니다. 이 두 모델은 다음과 같은 차이점이 있습니다.

Generative model: 주어진 입력 데이터(x)와 클래스(y)의 결합 확률 분포 P(x, y)를 학습하여 모델링합니다. 모델링된 분포를 이용해, 새로운 데이터를 생성할 수 있습니다. 언어 모델, Naive Bayes Classifier 등이 Generative model의 예시입니다.
Generative model은 데이터 x 가 생성되는 과정을 두 개의 확률모형, 즉 $P(y)$ , $P(x|y)$ 로 정의하고, 베이즈룰을 사용해 $P(y|x)$ 를 간접적으로 도출하는 모델입니다.

$$P(x,y) = P(x|y)P(y)$$

여기서 P(y)는 사전 확률(prior)로, 클래스 y의 발생 확률을 나타내며, P(x|y)는 y 클래스에서 x 데이터가 발생할 확률을 나타냅니다. 이 모델에서는 모든 클래스의 조건부 확률 분포를 학습하여, 주어진 새로운 데이터 x에 대해 가장 높은 확률을 가지는 클래스 y를 예측합니다.

Discriminative model: 입력 데이터(x)가 주어졌을 때 클래스(y)의 조건부 확률 분포 P(y|x)를 학습하여 모델링합니다. 모델링된 분포는 입력 데이터와 함께, 해당 데이터의 클래스를 예측하는데 사용됩니다. 예시로는 로지스틱 회귀, 서포트 벡터 머신 등이 있습니다.

$$P(y|x)$$

이 모델에서는 입력 데이터 x가 주어졌을 때, 해당 데이터의 클래스 y의 조건부 확률 분포를 학습합니다. 이 모델에서는 클래스 간 경계(decision boundary)를 찾는 것이 중요합니다. 새로운 데이터 x가 주어졌을 때, 입력 데이터 x에 대해 가장 높은 확률을 가지는 클래스 y를 예측합니다.

언어 모델에서도, 이 두 모델을 적용할 수 있습니다.

Generative model: 언어 모델을 Generative model로 바라보면, 주어진 문장의 확률 분포 P(w1, w2, ..., wn)를 모델링합니다. 이 모델을 이용해, 새로운 문장을 생성할 수 있습니다.

Discriminative model: 반면, 언어 모델을 Discriminative model로 바라보면, 이전 단어들이 주어졌을 때, 다음 단어의 확률 분포 P(wi+1|wi, ..., w1)를 모델링합니다. 이 모델을 이용해, 다음 단어를 예측할 수 있습니다.

일반적으로는 Discriminative model이 Generative model보다 더 강력한 모델로 알려져 있습니다. 그 이유는 Discriminative model이 학습 데이터에서 더 많은 정보를 추출할 수 있기 때문입니다. 그러나 이는 문제에 따라 다르며, 언어 모델 같은 경우에는 Generative model이 더 성능이 좋은 경우가 많습니다.

---

먼저, 생성모델과 판별모델의 목적 함수(objective function)를 각각 수식으로 표현해 보겠습니다.

생성모델(generative model)의 경우, 모든 변수 $x$와 클래스 $y$에 대한 결합 확률 분포를 학습하는 것이 목적입니다. 따라서, 로그 우도(log-likelihood)를 최대화하는 것이 목표입니다. 로그 우도는 다음과 같이 표현됩니다.

$$\max_{\theta} \sum_{i=1}^{n} \log P_{\theta}(x^{(i)}, y^{(i)})$$

여기서 $x^{(i)}$와 $y^{(i)}$는 각각 $i$번째 입력 데이터와 클래스를 나타내며, $\theta$는 모델 파라미터입니다.

판별모델(discriminative model)의 경우, 클래스 $y$가 주어졌을 때 입력 변수 $x$에 대한 조건부 확률 분포를 학습하는 것이 목적입니다. 따라서, 조건부 로그 우도(conditional log-likelihood)를 최대화하는 것이 목표입니다. 조건부 로그 우도는 다음과 같이 표현됩니다.

$$\max_{\theta} \sum_{i=1}^{n} \log P_{\theta}(y^{(i)} | x^{(i)})$$

여기서 $x^{(i)}$와 $y^{(i)}$는 각각 $i$번째 입력 데이터와 클래스를 나타내며, $\theta$는 모델 파라미터입니다.

예를 들어, 이진 분류 문제에서 생성모델과 판별모델의 차이를 살펴볼 수 있습니다. 생성모델은 클래스 $y$와 입력 변수 $x$에 대한 결합 확률 분포를 학습합니다. 이진 분류 문제에서는 클래스 $y$가 0 또는 1이므로, 생성모델은 다음과 같은 확률 분포를 학습합니다.

$$P(x,y) = P(x|y)P(y)$$

이와는 달리, 판별모델은 클래스 $y$가 주어졌을 때 입력 변수 $x$에 대한 조건부 확률 분포를 학습합니다. 이진 분류 문제에서는 판별모델은 다음과 같은 조건부 확률 분포를 학습합니다.

$$P(y|x)$$

즉, 생성모델은 클래스와 입력 변수에 대한 결합 분포를 학습하여 새로운 샘플을 생성할 수 있지만, 판별모델은 입력 변수에 대한 클래스를 직접 예측합니다
