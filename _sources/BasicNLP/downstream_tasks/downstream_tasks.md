# Downstream tasks

자연어 처리에서 Downstream task는 특정한 목적을 가진 다양한 자연어 처리 문제들을 의미합니다. 이러한 문제들은 텍스트 분류, 감성 분석, 기계 번역, 질문 답변 등이 있습니다. 이러한 Downstream task는 왜 하는 것일까요?

자연어처리에서 Downstream task를 하는 이유는 크게 두 가지로 나눌 수 있습니다.

첫째, 자연어처리는 컴퓨터가 자연어를 이해하고 처리할 수 있도록 하는 기술입니다. 하지만 자연어는 매우 복잡하고 다양하기 때문에, 하나의 모델로 모든 자연어 처리 작업을 수행하는 것은 어렵습니다. 이에 따라 자연어처리 모델을 다양한 Downstream task에 적용하여, 각각의 작업을 더 정확하게 수행할 수 있는 모델을 만드는 것이 중요합니다.

둘째, Downstream task를 수행함으로써 모델의 성능을 평가할 수 있습니다. 즉, 자연어처리 모델을 학습시키고 나면, 이 모델이 실제로 얼마나 잘 작동하는지를 평가할 필요가 있습니다. 이 때 Downstream task를 사용하여 모델의 성능을 평가하면, 모델이 실제로 다양한 자연어 처리 작업을 수행하는 능력을 평가할 수 있습니다.

따라서, Downstream task는 자연어처리에서 모델의 성능 향상과 모델 평가를 위해 중요한 역할을 합니다.

각각의 Downstream task에 대해 간단하게 설명해 보겠습니다.

- 텍스트 분류 (Text Classification): 주어진 텍스트를 미리 정의된 카테고리 중 하나로 분류하는 문제입니다. 예를 들어, 스팸 필터링이나 뉴스 분류 등에 사용됩니다.

- 감성 분석 (Sentiment Analysis): 주어진 텍스트의 긍정/부정/중립적인 감성을 분석하는 문제입니다. 예를 들어, 제품 리뷰나 소셜 미디어에서의 감성 분석 등에 사용됩니다.

- 개체명 인식 (Named Entity Recognition): 주어진 텍스트에서 인명, 지명, 날짜, 조직명 등의 명명체를 인식하는 문제입니다. 예를 들어, 정보 검색이나 정보 추출 등에 사용됩니다.

- 질문 답변 (Question Answering): 주어진 질문에 대한 답변을 찾는 문제입니다. 예를 들어, 인공지능 스피커나 검색 엔진 등에 사용됩니다.

- 기계 번역 (Machine Translation): 주어진 언어의 문장을 다른 언어로 번역하는 문제입니다. 예를 들어, 영어-한국어 번역이나 중국어-일본어 번역 등에 사용됩니다.

- 요약 (Summarization): 주어진 긴 문서를 요약하는 문제입니다. 예를 들어, 뉴스 기사 요약이나 문서 요약 등에 사용됩니다.

- 대화 모델링 (Conversational Modeling): 주어진 질문에 대해 인공지능이 답변하는 대화 모델링 문제입니다. 예를 들어, 챗봇 등에 사용됩니다.

- 문장 유사도 측정 (Semantic Textual Similarity): 두 문장이 얼마나 유사한지 측정하는 작업입니다. 이 작업은 텍스트 매칭, 표절 검출, 문장 분류 등에서 사용됩니다. 머신러닝, 딥러닝 모델을 사용하여 문장을 임베딩하고 코사인 유사도, 자카드 유사도 등과 같은 유사도 척도를 사용하여 문장 간 유사도를 측정합니다.

- 텍스트 생성 (Text Generation): 주어진 입력에 대해 새로운 텍스트를 생성하는 작업입니다. 예를 들어, 번역, 자유 형식 쓰기, 자동 이메일 응답 작성 등에서 사용됩니다. 이 작업은 다양한 기계학습 모델을 사용하여 수행됩니다. 대표적인 모델로는 RNN(순환 신경망), GPT(Generative Pre-trained Transformer) 등이 있습니다. 이러한 모델은 대규모 데이터셋을 학습하여 생성할 텍스트의 다양성과 품질을 높이는 데 사용됩니다. 예를 들어, GPT 모델은 사람과 유사한 대화를 생성하는 것으로 유명합니다.
