[Alpaca: A Strong, Replicable Instruction-Following Model](https://crfm.stanford.edu/2023/03/13/alpaca.html)

## Hello, Alpaca?

ìµœê·¼ LLaMaì´ì–´ì„œ ì•„ì£¼ í•«í•œ ëª¨ë¸ì´ ìˆìŠµë‹ˆë‹¤. ë°”ë¡œ Alpacaë¼ëŠ” ëª¨ë¸ì¸ë°ìš”. ì˜¤ëŠ˜ì€ Stanfordì—ì„œ ê³µê°œí•œ ì˜¤í”ˆì†ŒìŠ¤ì¸ Alpacaì— ëŒ€í•´ì„œ ê°„ë‹¨íˆ ì†Œê°œí•´ë³´ë ¤í•©ë‹ˆë‹¤.
Metaì—ì„œ ê³µê°œí•œ LLaMaë¼ëŠ” ì–¸ì–´ëª¨ë¸ì„ Stanford ë°•ì‚¬ê³¼ì • í•™ìƒë“¤ì´ ì‚¬ìš©ìì˜ ëª…ë ¹ì–´ì— ì–¸ì–´ëª¨ë¸ì´ ì˜ ë‹µë³€í•  ìˆ˜ ìˆë„ë¡ Instruction-following ë°ì´í„°ë¡œ íŒŒì¸íŠœë‹í•œ ëª¨ë¸ì…ë‹ˆë‹¤.
ì–¸ì–´ëª¨ë¸ì€ ê¸°ë³¸ì ìœ¼ë¡œ ë‹¤ìŒ ë‹¨ì–´ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ë¬¸ì œë¥¼ í’€ê¸° ë•Œë¬¸ì— ì¼ë°˜ì ì¸ ì‚¬ìš©ìì˜ ëª…ë ¹ì–´ì— ìì—°ìŠ¤ëŸ½ê²Œ ë‹µë³€í•˜ê¸°ê°€ ì–´ë ¤ìš´ë°ìš”. ê·¸ëŸ¼ì—ë„ ë¶ˆêµ¬í•˜ê³  ChatGPT ê°™ì€ ëª¨ë¸ì´ ë‹µë³€ì„ ì˜í•˜ëŠ” ê²ƒì€ ì‚¬ìš©ìì˜ ì˜ë„ì— ë§ê²Œ ëª¨ë¸ì„ Instruction-following ë°ì´í„°ë¡œ íŠœë‹ (Alignment) í–ˆê¸° ë•Œë¬¸ì´ë¼ê³ ë„ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê²°êµ­ ì‚¬ìš©ìê°€ ì–¸ì–´ëª¨ë¸ì„ ì˜ í™œìš©í•˜ê¸° ìœ„í•´ì„œëŠ” Instruction tuningì€ ê¼­ ê±°ì³ì•¼í•˜ëŠ” ê´€ë¬¸ì´ë¼ê³  í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
LLaMaë¥¼ íŠœë‹í•œ ëª¨ë¸ì´ë‹ˆ ì•„ë§ˆ ë¼ë§ˆì™€ ë¹„ìŠ·í•œ ìƒê¹€ìƒˆ ê°€ì§„ ì•ŒíŒŒì¹´ë¼ê³  ì´ë¦„ì„ ì§€ì€ê²Œ ì•„ë‹Œê°€ ì‹¶ë„¤ìš”ğŸ¤”

![image.png](https://devocean.sk.com/editorImg/2023/3/23/e61a09ac00cbff86421a28127c228355177ca171f85f2757aee6d21df3c5fdbd)

AlpacaëŠ” ë…¼ë¬¸ì´ ë”°ë¡œ ë°œí‘œë˜ì§„ ì•Šì•˜ì§€ë§Œ, ì–´ë–¤ ë°ì´í„°ë¡œ ì–´ë–»ê²Œ í•™ìŠµì„ í–ˆëŠ”ì§€ ì½”ë“œì™€ í•¨ê»˜ ê³µê°œê°€ ë˜ì–´ìˆì–´ì„œ í˜„ì¬ì‹œì ì—ì„œë„ LLaMaì™€ ê°™ì´ ë§ì€ ë³€í˜• ë° ì–´í”Œë¦¬ì¼€ì´ì…˜ì´ ë‚˜ì˜¤ê³  ìˆëŠ”ë°ìš”. ì§€ê¸ˆë¶€í„° í•œë²ˆ ì•Œì•„ë³´ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤.

## Alpacaë¥¼ ì™œ ë§Œë“¤ì—ˆì„ê¹Œ?

Stanford í•™ìƒë“¤ì€ ChatGPT, Claude, Bing Chatë“± ë‹¤ì–‘í•œ ëª¨ë¸ì´ ì´ë¯¸ í›Œë¥­í•œ ì„±ëŠ¥ì„ ë³´ì—¬ì£¼ê³  ìˆì§€ë§Œ ê·¸ëŸ¼ì—ë„ ë¶ˆêµ¬í•˜ê³  ì•„ì§ì€ ë¶€ì¡±í•œ ì ì´ ìˆë‹¤ê³  ì§€ì í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ë©´, ì˜ëª»ëœ ì •ë³´ë¥¼ ìƒì„±í•˜ê±°ë‚˜, ì‚¬íšŒì ì¸ í¸ê²¬ ë° ë¶ˆí¸í•œ ë§ë“¤ì„ ìƒì„±í•˜ëŠ” ê²ƒì´ì£ . ì´ëŸ¬í•œ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ í•™ê³„ì™€ì˜ í˜‘ì—…ì´ í•„ìš”í•˜ì§€ë§Œ OpenAIì˜ `text-davinci-003`ê³¼ ê°™ì€ ëª¨ë¸ì€ ì ‘ê·¼í•˜ê¸° í˜ë“  closed-source modelì´ê¸° ë•Œë¬¸ì— ì—°êµ¬ì— ì–´ë ¤ì›€ì´ ìˆë‹¤ê³  ë§í•©ë‹ˆë‹¤ğŸ¥²
ë§ˆì¹¨ Metaì—ì„œ LLaMaë¥¼ ê³µê°œí–ˆê³ , ê¸°ì¡´ì— ì•Œë ¤ì§„ ì—°êµ¬ë¥¼ ë°”íƒ•ìœ¼ë¡œ í›¨ì”¬ ì €ë ´í•œ ë¹„ìš©ìœ¼ë¡œ ëª¨ë¸ì„ í•™ìŠµí•  ìˆ˜ ìˆë„ë¡, ë°ì´í„° ë° ëª¨ë¸ í•™ìŠµ ë°©ë²•ì„ ì¬í˜„ ê°€ëŠ¥í•˜ë„ë¡ ê³µê°œí•œ ê²ƒìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤.
ê²°ê³¼ì ìœ¼ë¡œ, AlpacaëŠ” text-davinci-003(175B)ë³´ë‹¤ í›¨ì”¬ ì‘ì€ 7B ëª¨ë¸ì´ì§€ë§Œ ìœ ì‚¬í•˜ê²Œ ë™ì‘í•œë‹¤ê³  í•©ë‹ˆë‹¤.
[Gradio ê¸°ë°˜ ë°ëª¨ í˜ì´ì§€](https://alpaca-ai.ngrok.io/)ë„ ê³µê°œí–ˆëŠ”ë°, ì ‘ì†ì€ ê°€ë” ì•ˆë˜ëŠ” ê²ƒ ê°™ë„¤ìš”ğŸ¤”
![image.png](https://devocean.sk.com/editorImg/2023/3/23/c0b4da8b95c774dfc242df286f8ddde97cb4aef73ed9ade7233f3d6d1d3fe741)
AlpacaëŠ” academic researchì— í•œí•´ì„œë§Œ ì‚¬ìš©ì´ ê°€ëŠ¥í•˜ê³  ìƒì—…ì  ì‚¬ìš©ì€ ê¸ˆì§€í•˜ê³  ìˆëŠ”ë°ìš”.
ì´ìœ ëŠ” LLaMaì˜ ë¼ì´ì„¼ìŠ¤ê°€ [non-commercial ë¼ì´ì„¼ìŠ¤](https://docs.google.com/forms/d/e/1FAIpQLSfqNECQnMkycAp2jP4Z9TFX0cGR4uf7b_fBxjY_OjhJILlKGA/viewform)ë¼ëŠ”ì  ê·¸ë¦¬ê³  [OpenAIì˜ tet-davinci-003ì—ì„œ ì–»ì–´ë‚¸ ë°ì´í„°ë¥¼ í™œìš©í–ˆë‹¤ëŠ” ì ](https://openai.com/policies/terms-of-use)ë“±ì„ ì´ìœ ë¡œ ì œì‹œí•˜ê³  ìˆìŠµë‹ˆë‹¤.

## í•™ìŠµ ë°©ë²•

AlpacaëŠ” ê¸°ë³¸ì ìœ¼ë¡œ 7B í¬ê¸°ì˜ LLaMaë¥¼ Backboneìœ¼ë¡œ ë‘ê³  Instruction tuningì„ í•œ ëª¨ë¸ì…ë‹ˆë‹¤.
ëª¨ë¸ì€ ì´ë¯¸ ê³µê°œë˜ì–´ìˆê¸° ë•Œë¬¸ì— ê°€ì¥ ì¤‘ìš”í•œ ê²ƒì€ ë°ì´í„°ì¸ë°ìš”. ê¸°ì¡´ì— Instruction-following ë°ì´í„°ë¥¼ ìƒì„±í•˜ê¸° ìœ„í•œ ë§ì€ ì—°êµ¬ê°€ ìˆì—ˆê³  ì‘ë…„ 12ì›”ì¸ ìµœê·¼ì— ê³µê°œëœ [self-Instruct](https://github.com/yizhongw/self-instruct)ë¼ëŠ” ì—°êµ¬ë¥¼ ì°¸ê³ í•´ì„œ ë°ì´í„°ë¥¼ ìƒì„±í–ˆìŠµë‹ˆë‹¤.
self-Instructì˜ í•µì‹¬ì€ LLM(Large Language Model)ë¡œ ë°ì´í„°ë¥¼ ìƒì„±í•´ì„œ ê·¸ ë°ì´í„°ë¡œ ë‹¤ì‹œ LLMì„ í•™ìŠµí•œë‹¤ëŠ” ê²ƒì¸ë°ìš”, í•œ ë§ˆë””ë¡œ íŠœë‹ì„ ìœ„í•œ ë°ì´í„°ë„ ëª¨ë¸ì´ ìƒì„±í•˜ëŠ” ìê°€ìˆ˜ê¸‰ ì‹œìŠ¤í…œ(?)ì´ë¼ê³  ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
Alpacaì—ì„œëŠ” self-Instructì˜ ë°©ë²•ë¡ ì„ ì¡°ê¸ˆ ë‹¨ìˆœí™”í•˜ë˜ ëª¨ë¸ì€ ë” ì¢‹ì€ ëª¨ë¸([GPT-3(davinci) -> GPT-3.5(text-davinci-003)](https://platform.openai.com/docs/model-index-for-researchers/models-referred-to-as-gpt-3-5))ì„ ì‚¬ìš©í•´ì„œ ë°ì´í„°ë¥¼ ìƒì„±í–ˆìŠµë‹ˆë‹¤.

##### ë°ì´í„° ìƒì„± ì˜ˆì‹œ

Alpacaì—ì„œ ê³µê°œí•œ ë°©ë²•ëŒ€ë¡œ ë°ì´í„°ê°€ ìƒì„±ë˜ëŠ”ì§€ [OpenAI playground](https://platform.openai.com/playground)ì—ì„œ í…ŒìŠ¤íŠ¸ë¥¼ í•´ë³´ì•˜ìŠµë‹ˆë‹¤.
ì•„ë˜ ë³´ì´ëŠ” ì˜ˆì‹œì™€ ê°™ì´ ë°ì´í„° ìƒì„±ì´ ì˜ ë˜ëŠ” ê²ƒì„ í™•ì¸ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

###### í•œêµ­ì–´ ê²°ê³¼
![alpaca-self-gen-korean](https://user-images.githubusercontent.com/7252598/225496927-2df4614a-8e35-4032-b65a-54e898ca61e6.gif)

###### ì˜ì–´ ê²°ê³¼
![alpaca-gen-self-instruct-en](https://user-images.githubusercontent.com/7252598/225496953-69f90efb-a20e-4147-bf4a-df623fc33e83.gif)

ìœ„ì™€ ê°™ì€ ê³¼ì •ì„ ë°˜ë³µí•˜ë©´ì„œ ì‚¬ëŒì´ ì§ì ‘ ë§Œë“  175ê°œì˜ seed ë°ì´í„°ì…‹ì„ ê¸°ë°˜ìœ¼ë¡œ ë°ì´í„°ë¥¼ ì•½ 52,000ê°œê¹Œì§€ ì¶”ê°€ ìƒì‚°ì„ í•˜ê³ , ì´ ë°ì´í„°ë¥¼ í•™ìŠµì…‹ìœ¼ë¡œ í™œìš©í–ˆìŠµë‹ˆë‹¤.
![image.png](https://devocean.sk.com/editorImg/2023/3/23/1ea18693744d12a835878563919dca568be6bc15017abc8541cf1e969aca5e0d)
ë°ì´í„°ì˜ í’ˆì§ˆì´ ë§¤ìš° ë›°ì–´ë‚˜ë‹¤ê³  í•  ìˆ˜ëŠ” ì—†ê² ì§€ë§Œ ëª¨ë¸ì„ Alignmentí•˜ê¸°ì—ëŠ” ì–´ëŠì •ë„ ì¶©ë¶„í•œ ë°ì´í„°ë¥¼ ìƒì„±í•œ ê²ƒìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤. (52,000ê±´ì˜ ë°ì´í„°ë¥¼ ìƒì„±í•˜ëŠ”ë°ëŠ” `$500` ì •ë„ì˜ ë¹„ìš©ì´ ë“¤ì—ˆë‹¤ê³  í•©ë‹ˆë‹¤)
self-Instructë¡œ ìƒì„±í•œ ë°ì´í„°ë¡œ A100(80GB) 8ëŒ€ë¡œ Supervised Fintuning(SFT)í•˜ë©´ 3 epochì— 3ì‹œê°„ì •ë„ ì†Œìš”ë˜ë©°, ì¼ë°˜ì ì¸ ëª…ë ¹ì–´ì—ë„ ì˜ ë‹µë³€í•  ìˆ˜ ìˆëŠ” ëª¨ë¸ì´ íƒ„ìƒí•˜ê²Œ ë©ë‹ˆë‹¤. (ì´ë•Œ ë°œìƒí•œ ë¹„ìš©ì€ $100 ì´í•˜ë¡œ ë“¤ì—ˆë‹¤ê³  í•©ë‹ˆë‹¤)


###### prompt
- requirement í…œí”Œë¦¿ì—ë‹¤ê°€ seed_task ì…ë ¥í•´ë†“ìŒ defaultëŠ” 3ê°œ!
```python
def encode_prompt(prompt_instructions):
    """Encode multiple prompt instructions into a single string."""
    prompt = open("./prompt.txt").read() + "\n"

    for idx, task_dict in enumerate(prompt_instructions):
        (instruction, input, output) = task_dict["instruction"], task_dict["input"], task_dict["output"]
        instruction = re.sub(r"\s+", " ", instruction).strip().rstrip(":")
        input = "<noinput>" if input.lower() == "" else input
        prompt += f"###\n"
        prompt += f"{idx + 1}. Instruction: {instruction}\n"
        prompt += f"{idx + 1}. Input:\n{input}\n"
        prompt += f"{idx + 1}. Output:\n{output}\n"
    prompt += f"###\n"
    prompt += f"{idx + 2}. Instruction:"
    return prompt

def generate_instruction_following_data(
    output_dir="./",
    seed_tasks_path="./seed_tasks.jsonl",
    num_instructions_to_generate=100,
    model_name="text-davinci-003",
    num_prompt_instructions=3,
    request_batch_size=5,
    temperature=1.0,
    top_p=1.0,
    num_cpus=16,
):
    seed_tasks = [json.loads(l) for l in open(seed_tasks_path, "r")]
    seed_instruction_data = [
        {"instruction": t["instruction"], "input": t["instances"][0]["input"], "output": t["instances"][0]["output"]}
        for t in seed_tasks
    ]
    print(f"Loaded {len(seed_instruction_data)} human-written seed instructions")

    os.makedirs(output_dir, exist_ok=True)
    request_idx = 0
    # load the LM-generated instructions
    machine_instruction_data = []
    if os.path.exists(os.path.join(output_dir, "regen.json")):
        machine_instruction_data = utils.jload(os.path.join(output_dir, "regen.json"))
        print(f"Loaded {len(machine_instruction_data)} machine-generated instructions")

    # similarities = {}
    scorer = rouge_scorer.RougeScorer(["rougeL"], use_stemmer=False)

    # now let's generate new instructions!
    progress_bar = tqdm.tqdm(total=num_instructions_to_generate)
    if machine_instruction_data:
        progress_bar.update(len(machine_instruction_data))

    # first we tokenize all the seed instructions and generated machine instructions
    all_instructions = [d["instruction"] for d in seed_instruction_data] + [
        d["instruction"] for d in machine_instruction_data
    ]
    all_instruction_tokens = [scorer._tokenizer.tokenize(inst) for inst in all_instructions]

    while len(machine_instruction_data) < num_instructions_to_generate:
        request_idx += 1

        batch_inputs = []
        for _ in range(request_batch_size):
            # only sampling from the seed tasks
            prompt_instructions = random.sample(seed_instruction_data, num_prompt_instructions)
            prompt = encode_prompt(prompt_instructions)
            batch_inputs.append(prompt)
        decoding_args = utils.OpenAIDecodingArguments(
            temperature=temperature,
            n=1,
            max_tokens=3072,  # hard-code to maximize the length. the requests will be automatically adjusted
            top_p=top_p,
            stop=["\n20", "20.", "20."],
        )

```

````
20ê°œì˜ ë‹¤ì–‘í•œ task instruction ì„¸íŠ¸ë¥¼ ì‘ì„±í•˜ë¼ëŠ” ìš”ì²­ì„ ë°›ìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ task instructionì€ GPT ëª¨ë¸ì— ì œê³µë˜ë©° instructionì„ ì™„ë£Œí•˜ê¸° ìœ„í•´ GPT ëª¨ë¸ì„ í‰ê°€í•©ë‹ˆë‹¤.

ìš”êµ¬ ì‚¬í•­ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.
1. ë‹¤ì–‘ì„±ì„ ê·¹ëŒ€í™”í•˜ê¸° ìœ„í•´ ê° instructionì— ëŒ€í•´ ë™ì‚¬ë¥¼ ë°˜ë³µí•˜ì§€ ë§ˆì‹­ì‹œì˜¤.
2. instructionì— ì‚¬ìš©ë˜ëŠ” ì–¸ì–´ë„ ë‹¤ì–‘í•´ì•¼ í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ëª…ë ¹í˜• instructionê³¼ ì§ˆë¬¸ì„ ê²°í•©í•´ì•¼ í•©ë‹ˆë‹¤.
3. instructionì˜ ì¢…ë¥˜ê°€ ë‹¤ì–‘í•´ì•¼ í•œë‹¤. ëª©ë¡ì—ëŠ” open-ended ìƒì„±, ë¶„ë¥˜, í¸ì§‘ ë“±ê³¼ ê°™ì€ ë‹¤ì–‘í•œ ìœ í˜•ì˜ ì‘ì—…ì´ í¬í•¨ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.
2. GPT ì–¸ì–´ ëª¨ë¸ì€ instructionì„ ì™„ë£Œí•  ìˆ˜ ìˆì–´ì•¼ í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´ ì–´ì‹œìŠ¤í„´íŠ¸ì—ê²Œ ì‹œê°ì , ì‚¬ì§„, ì´ë¯¸ì§€ ë˜ëŠ” ì˜¤ë””ì˜¤ ì¶œë ¥ê³¼ ê´€ë ¨ëœ instructionì„ ìƒì„±í•˜ì§€ ë§ˆì‹­ì‹œìš”. ë˜ ë‹¤ë¥¸ ì˜ˆë¥¼ ë“¤ë©´ ì–´ì‹œìŠ¤í„´íŠ¸ì—ê²Œ ì˜¤í›„ 5ì‹œì— ê¹¨ìš°ë¼ê³  ìš”ì²­í•˜ê±°ë‚˜ ì–´ë–¤ ì‘ì—…ë„ ìˆ˜í–‰í•  ìˆ˜ ì—†ê¸° ë•Œë¬¸ì— ë¯¸ë¦¬ ì•Œë¦¼ì„ ì„¤ì •í•˜ì§€ ë§ˆì‹­ì‹œì˜¤.
3. instructionëŠ” í•œêµ­ì–´ë¡œ ì‘ì„±í•´ì•¼ í•©ë‹ˆë‹¤.
4. instructionì€ 1~2ë¬¸ì¥ì´ì–´ì•¼ í•©ë‹ˆë‹¤. ëª…ë ¹í˜• ë¬¸ì¥ì´ë‚˜ ì§ˆë¬¸ì´ í—ˆìš©ë©ë‹ˆë‹¤.
5. instructionì— ëŒ€í•œ ì ì ˆí•œ ì…ë ¥ì„ ìƒì„±í•´ì•¼ í•©ë‹ˆë‹¤. ì…ë ¥ í•„ë“œì—ëŠ” instructionì— ëŒ€í•´ ì œê³µëœ íŠ¹ì • ì˜ˆê°€ í¬í•¨ë˜ì–´ì•¼ í•©ë‹ˆë‹¤. í˜„ì‹¤ì ì¸ ë°ì´í„°ë¥¼ í¬í•¨í•´ì•¼ í•˜ë©° ë‹¨ìˆœí•œ ìë¦¬ í‘œì‹œìë¥¼ í¬í•¨í•´ì„œëŠ” ì•ˆ ë©ë‹ˆë‹¤. ì…ë ¥ ë‚´ìš©ì€ instructionì„ ì–´ë µê²Œ ë§Œë“¤ ìˆ˜ ìˆëŠ” ì‹¤ì§ˆì ì¸ ë‚´ìš©ì„ ì œê³µí•´ì•¼ í•˜ì§€ë§Œ ì´ìƒì ìœ¼ë¡œëŠ” 100ë‹¨ì–´ë¥¼ ì´ˆê³¼í•˜ì§€ ì•Šì•„ì•¼ í•©ë‹ˆë‹¤.
6. ëª¨ë“  instructionì— ì…ë ¥ì´ í•„ìš”í•œ ê²ƒì€ ì•„ë‹™ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, instructionì´ "ì„¸ê³„ì—ì„œ ê°€ì¥ ë†’ì€ ë´‰ìš°ë¦¬ëŠ” ë¬´ì—‡ì…ë‹ˆê¹Œ?"ì™€ ê°™ì€ ì¼ë°˜ì ì¸ ì •ë³´ì— ëŒ€í•´ ë¬»ëŠ” ê²½ìš° íŠ¹ì • ì»¨í…ìŠ¤íŠ¸ë¥¼ ì œê³µí•  í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤. ì´ ê²½ìš° ì…ë ¥ í•„ë“œì— "<noinput>"ì„ ë„£ê¸°ë§Œ í•˜ë©´ ë©ë‹ˆë‹¤.
7. ì¶œë ¥ì€ instructionê³¼ ì…ë ¥ì— ëŒ€í•œ ì ì ˆí•œ ì‘ë‹µì´ì–´ì•¼ í•©ë‹ˆë‹¤. ì¶œë ¥ì´ 100ë‹¨ì–´ ë¯¸ë§Œì¸ì§€ í™•ì¸í•˜ì‹­ì‹œì˜¤.

20ê°œ Task instruction ëª©ë¡:
````


###### HFë¡œ í•™ìŠµ ë° FSDP ì‚¬ìš©
- python 3.10 ì‚¬ìš©
```sh
torchrun --nproc_per_node=4 --master_port=<your_random_port> train.py \
    --model_name_or_path <your_path_to_hf_converted_llama_ckpt_and_tokenizer> \
    --data_path ./alpaca_data.json \
    --bf16 True \
    --output_dir <your_output_dir> \
    --num_train_epochs 3 \
    --per_device_train_batch_size 4 \
    --per_device_eval_batch_size 4 \
    --gradient_accumulation_steps 8 \
    --evaluation_strategy "no" \
    --save_strategy "steps" \
    --save_steps 2000 \
    --save_total_limit 1 \
    --learning_rate 2e-5 \
    --weight_decay 0. \
    --warmup_ratio 0.03 \
    --lr_scheduler_type "cosine" \
    --logging_steps 1 \
    --fsdp "full_shard auto_wrap" \
    --fsdp_transformer_layer_cls_to_wrap 'LLaMADecoderLayer' \
    --tf32 True

```

# Assets released
- Demo: An [interactive demo](https://crfm.stanford.edu/alpaca/) for everyone to try out Alpaca.
- Data: [52K demonstrations](https://github.com/tatsu-lab/stanford_alpaca#data-release) used to fine-tune Alpaca.
- Data generation process: the code for [generating the data](https://github.com/tatsu-lab/stanford_alpaca#data-generation-process).
- Hyperparameters: for [fine-tuning](https://github.com/tatsu-lab/stanford_alpaca#fine-tuning) the model using the Hugging Face API.

## ê³µê°œëœ Data ì˜ˆì‹œ
![image](https://user-images.githubusercontent.com/7252598/225485522-f6c9a03e-2eac-4473-ba66-9d61b22217ff.png)

- ëª¨ë¸ ë° í•™ìŠµ ì½”ë“œ ê³µê°œ
  - Training code: our code uses the [Hugging Face interface to LLaMA](https://github.com/huggingface/transformers/pull/21955). As of now, the effort to support LLaMA is still ongoing and not stable. We will give the exact training commands once Hugging Face supports LLaMA officially.
  - [ì•„ë˜ì—ì„œ IGNORE_INDEX ë¶€ë¶„ì´ ì¤‘ìš”!](https://github.com/tatsu-lab/stanford_alpaca/blob/61a3b4324505d284200a35dcbf1cc5e438ff2b46/train.py#L133)

```python
def preprocess(
    sources: Sequence[str],
    targets: Sequence[str],
    tokenizer: transformers.PreTrainedTokenizer,
) -> Dict:
    """Preprocess the data by tokenizing."""
    examples = [s + t for s, t in zip(sources, targets)]
    examples_tokenized, sources_tokenized = [_tokenize_fn(strings, tokenizer) for strings in (examples, sources)]
    input_ids = examples_tokenized["input_ids"]
    labels = copy.deepcopy(input_ids)
    for label, source_len in zip(labels, sources_tokenized["input_ids_lens"]):
        label[:source_len] = IGNORE_INDEX
    return dict(input_ids=input_ids, labels=labels)

```

## ë§ˆì¹˜ë©°

Stable Diffusionê³¼ ê°™ì´ LLaMaë„ ê³µê°œê°€ ë˜ë©´ì„œ ë‹¤ì–‘í•œ í›„ì† ëª¨ë¸ë“¤ì´ ë¹ ë¥´ê²Œ ë‚˜ì˜¤ê³  ìˆìŠµë‹ˆë‹¤.
ë²Œì¨ 8-bit ì–‘ìí™”ì™€ LoRA(Low-Rank Adaption)ë“±ì„ í™œìš©í•´ì„œ ëŒ€í˜•ì–¸ì–´ëª¨ë¸ì„ ê°œì¸ PCì—ì„œë„ ì‰½ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆê²Œ í•˜ëŠ” í”„ë¡œì íŠ¸ë“¤ì´ ê°œë°œë˜ê³  ìˆê³ , ì´ë¯¸ í•œêµ­ì–´ë¡œ íŠœë‹ëœ [7B KoAlpaca ëª¨ë¸](https://github.com/Beomi/KoAlpaca), [65B ëª¨ë¸](https://huggingface.co/beomi/KoAlpaca-65B-LoRA?fbclid=IwAR3Damgr8gvwhqaSwwoOP-iHC5TepVhf9Gz2rlvpehOcAaplvGHjiH_RrBk)ë„ ë“±ì¥í–ˆìŠµë‹ˆë‹¤.
ì•ìœ¼ë¡œëŠ” ì´ì „ë³´ë‹¤ ë” ì €ë ´í•œ ë¹„ìš©ìœ¼ë¡œ ë” ê´œì°®ì€ ì„±ëŠ¥ì˜ ëª¨ë¸ë“¤ì„ ì ì  ë” ë§ì´ ì‚¬ìš©í•  ìˆ˜ ìˆê²Œ ë ê¹Œìš”?
ê°œì„ í•  ë¶€ë¶„ì€ ë§ê² ì§€ë§Œ ì˜¤í”ˆì†ŒìŠ¤ ìƒíƒœê³„ì—ì„œ Alpacaì˜ ë“±ì¥ì€ ê·¸ëŸ¬í•œ ë¯¸ë˜ì— ë¶„ëª… ë„ì›€ì´ ë  ê²ƒìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤.
ë¨¼ ë¯¸ë˜ê°€ ì•„ë‹ˆë¼ ì§€ê¸ˆì´ë¼ë„ ì¡°ê¸ˆì€ ë” ë˜‘ë˜‘í•˜ê³  ì¬ë¯¸ìˆëŠ” ìì‹ ë§Œì˜ ì–¸ì–´ëª¨ë¸ì„ ë§Œë“¤ê³  ì‹¶ë‹¤ë©´ ì§€ê¸ˆ `Alpaca`ë¥¼ ì‚¬ìš©í•´ë³´ì‹œëŠ”ê±´ ì–´ë–¨ê¹Œìš”?ğŸ™‚

## ì°¸ê³ ìë£Œ

* [Alpaca: A Strong, Replicable Instruction-Following Model](https://crfm.stanford.edu/2023/03/13/alpaca.html)
* [Alpaca github](https://github.com/tatsu-lab/stanford_alpaca#authors)
* [KoAlpaca](https://github.com/Beomi/KoAlpaca)
