# Overview

자연어 처리(Natural Language Processing, NLP)는 인간 언어를 이해하고 처리하는 인공지능 기술로, 현재는 다양한 분야에서 활용되고 있습니다. NLP의 발전 역사는 굉장히 오래되었지만, 이를 크게 세 가지 시기로 나누어 볼 수 있습니다.

#### 1. 규칙 기반 (1950년대~1980년대)

NLP의 초기에는 규칙 기반 방법이 주로 사용되었습니다. 이 방법은 언어를 처리하기 위한 규칙을 사람이 수작업으로 작성하고, 이를 컴퓨터가 처리하는 방법입니다. 대표적인 예가 ELIZA입니다. ELIZA는 사용자와의 대화를 통해 상담을 제공하는 프로그램으로, 입력된 문장에서 일부 키워드를 추출하여 관련된 응답을 생성하는 방식으로 작동했습니다. 규칙 기반 방식은 문법적인 오류를 줄일 수 있으나, 모든 자연어를 커버하는 규칙을 작성하는 것은 어려움이 있었습니다.

#### 2. 통계 기반 (1990년대~2010년대 초)

1990년대 이후부터는 통계 기반 방법이 대세가 되었습니다. Bag-of-Words (BoW)와 함께 발전한 방법으로, BoW는 단어 빈도를 이용하여 문서를 벡터로 표현하고, 이를 이용하여 문서 분류 및 유사성 검색 등을 수행할 수 있습니다. BOW는 간단하고 이해하기 쉬우며, 현재까지도 많이 사용됩니다. 
통계 기반 방법은 자연어 데이터를 바탕으로 통계 모델을 학습하고, 이를 이용하여 자연어를 처리합니다. 대표적으로는 히든 마르코프 모델(Hidden Markov Model), 조건부 랜덤 필드(Conditional Random Fields), 나이브 베이즈(Naive Bayes) 분류기 등이 있습니다.

#### 3. 딥러닝 기반 (2010년대 후반~현재)

딥 러닝 기반 자연어 처리는 2010년대 이후 발전한 방법으로, 특히 딥 러닝의 발전과 함께 더욱 발전해왔습니다. 이 방법은 딥 러닝 모델을 이용하여 자연어를 처리하는 것으로, 대표적인 예로는 CNN이나 LSTM이 있습니다. 이 방법은 통계 기반 방식보다 더욱 정확한 처리가 가능하며, 최근에는 다양한 자연어 처리 태스크에서 SOTA(Sate-of-the-Art) 성능을 보이고 있습니다.

#### 4. 사전 훈련 기반 자연어 처리 (2018년~현재)
사전 훈련 기반 자연어 처리는 대규모의 텍스트 데이터를 이용하여 모델을 사전 훈련시킨 다음, 이를 다른 자연어 처리 태스크에 fine-tuning을 통해 이용하는 방법입니다. 이 방법은 전이 학습과 밀접한 관련이 있으며, 대표적인 예로는 BERT와 GPT가 있습니다. 이 방법은 대규모의 자연어 처리 태스크에서 높은 성능을 보이고 있으며, 다양한 자연어 처리 태스크에서 사용되고 있습니다.

#### 5. 대형 언어 모델 기반 자연어 처리 (2020년~현재)
대형 언어 모델 기반 자연어 처리는 대규모의 데이터를 이용하여 사전 훈련시킨 후 다양한 자연어 처리 태스크를 수행하는 방식으로 동작합니다. 이 방법은 LLMs(Language Models)라고도 불리며, 대표적인 예로는 GPT-3가 있습니다. LLMs는 in-context learning과 instruction tuning을 포함하여 학습된 모델을 의미하며, 이 방법은 다양한 자연어 처리 태스크에서 높은 성능을 보이고 있습니다. 특히 자연어 생성 분야에서 큰 주목을 받고 있으며, 최근에는 다양한 분야에서 활용될 것으로 기대됩니다.
