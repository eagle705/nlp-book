
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Parameter Efficient Fine-Tuning(PEFT) &#8212; NLP Book</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=796348d33e8b1d947c94" rel="stylesheet">
<link href="../_static/styles/bootstrap.css?digest=796348d33e8b1d947c94" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=796348d33e8b1d947c94" rel="stylesheet">

  
  <link href="../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=796348d33e8b1d947c94" rel="stylesheet">
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2">
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2">
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=4ec06e9971c5264fbd345897d5258098f11cc577" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=796348d33e8b1d947c94">
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=796348d33e8b1d947c94">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=8bf782fb4ee92b3d3646425e50f299c4e1fd152d"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script async="async" src="https://www.googletagmanager.com/gtag/js?id=G-RCPD8XLR5D"></script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'G-RCPD8XLR5D');
            </script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'ChatGPT/PEFT';</script>
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Introduction" href="../DevChatGPT/introduction.html" />
    <link rel="prev" title="Hello, Alpaca?" href="Alpaca.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="docsearch:language" content="en">
  </head>
  
  
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="180" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>

  
  <input type="checkbox" class="sidebar-toggle" name="__primary" id="__primary">
  <label class="overlay overlay-primary" for="__primary"></label>

  
  <input type="checkbox" class="sidebar-toggle" name="__secondary" id="__secondary">
  <label class="overlay overlay-secondary" for="__secondary"></label>

  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
      
<form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false">
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
    </div>
  </div>

  
  <nav class="bd-header navbar navbar-expand-lg bd-navbar" id="navbar-main"><div class="bd-header__inner bd-page-width">
  <label class="sidebar-toggle primary-toggle" for="__primary">
      <span class="fa-solid fa-bars"></span>
  </label>
  <div id="navbar-start">
    
    
  


<a class="navbar-brand logo" href="../intro.html">

  
  
  
  
  
  
  

  
    <img src="../_static/logo.png" class="logo__image only-light" alt="Logo image">
    <img src="../_static/logo.png" class="logo__image only-dark" alt="Logo image">
  
  
</a>
    
  </div>

  
  <div class="col-lg-9 navbar-header-items">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <nav class="navbar-nav">
    <p class="sidebar-header-items__title" role="heading" aria-level="1" aria-label="Site Navigation">
        Site Navigation
    </p>
    <ul id="navbar-main-elements" class="navbar-nav">
        
                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../Setup/setup.html">
                        Setup
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../NLP/nlp.html">
                        Natural Language Processing
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../BasicNLP/overview/overview.html">
                        Overview
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../BasicNLP/text_representation/text_representation.html">
                        Text Representation
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../BasicNLP/dl_nlp/dl_nlp.html">
                        Deep Learning for NLP
                      </a>
                    </li>
                
            <div class="nav-item dropdown">
                <button class="btn dropdown-toggle nav-item" type="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                    More
                </button>
                <div class="dropdown-menu">
                    
                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../BasicNLP/LM/LM.html">
                        Language Model
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../Transformer/architecture/introduction.html">
                        Introduction
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../Transformer/architecture/transformer_family.html">
                        Transformer Family
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../TransformerModels/introduction.html">
                        Transformer models
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../Exercise/introduction.html">
                        Downstream Task
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../Exercise/sentiment_analysis.html">
                        감성분석 (Sentiment Analysis)
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../Exercise/Making_Transformers_Efficient_in_Production.html">
                        Making Transformers Efficient in Production
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../Exercise/Training_Transformers_from_Scratch.html">
                        Training Transformers from Scratch
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../LLM/introduction.html">
                        Introduction
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../LLM/distributed_application.html">
                        PyTorch로 분산어플리케이션 개발하기
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../LLM/slurm.html">
                        SLURM
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="introduction.html">
                        Introduction
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="LLaMA.html">
                        Meta가 쏘아올린 작은공 LLaMA
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="Alpaca.html">
                        Hello, Alpaca?
                      </a>
                    </li>
                

                    <li class="nav-item current active">
                      <a class="nav-link nav-internal" href="#">
                        Parameter Efficient Fine-Tuning(PEFT)
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../DevChatGPT/introduction.html">
                        Introduction
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../Appendix/appendix.html">
                        Appendix
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../Appendix/DeepLearningMath/calculus.html">
                        미분과 그래디언트
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../Appendix/DeepLearningMath/MLE.html">
                        MLE (Maximum Likelihood Estimation)
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../Appendix/DeepLearningMath/MAP.html">
                        MAP (Maximum A P Posteriori Estimation)
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../Appendix/DeepLearningMath/naiveBayesClassifier.html">
                        Naive Bayes Classifier
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../Appendix/Entropy/informationEntropy.html">
                        정보와 엔트로피
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../Appendix/Entropy/jointConditionalEntropy.html">
                        Joint Entropy와 Conditional Entropy
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../Appendix/Entropy/crossEntropyKLDivergence.html">
                        Mutual Information, Cross Entropy 그리고 KL Divergence까지
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../Appendix/LinearAlgebra/eigenvectorvalue.html">
                        Eigenvector와 Eigenvalue
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../Appendix/LinearAlgebra/eigen_example.html">
                        Eigenvector와 Eigenvalue를 활용한 PCA 예시
                      </a>
                    </li>
                
                </div>
            </div>
            
    </ul>
</nav>
      </div>
      
    </div>

    <div id="navbar-end">
      
        <div class="navbar-end-item navbar-persistent--container">
          
<button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-toggle="tooltip">
  <i class="fa-solid fa-magnifying-glass"></i>
</button>
        </div>
      
      
      <div class="navbar-end-item">
        <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
</button>
      </div>
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
      </ul>
      </div>
      
    </div>
  </div>


  
  
    <div class="navbar-persistent--mobile">
<button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-toggle="tooltip">
  <i class="fa-solid fa-magnifying-glass"></i>
</button>
    </div>
  

  
  <label class="sidebar-toggle secondary-toggle" for="__secondary">
      <span class="fa-solid fa-outdent"></span>
  </label>
  

</div>
  </nav>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        
  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
      
      <div class="navbar-center-item">
        <nav class="navbar-nav">
    <p class="sidebar-header-items__title" role="heading" aria-level="1" aria-label="Site Navigation">
        Site Navigation
    </p>
    <ul id="navbar-main-elements" class="navbar-nav">
        
                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../Setup/setup.html">
                        Setup
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../NLP/nlp.html">
                        Natural Language Processing
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../BasicNLP/overview/overview.html">
                        Overview
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../BasicNLP/text_representation/text_representation.html">
                        Text Representation
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../BasicNLP/dl_nlp/dl_nlp.html">
                        Deep Learning for NLP
                      </a>
                    </li>
                
            <div class="nav-item dropdown">
                <button class="btn dropdown-toggle nav-item" type="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                    More
                </button>
                <div class="dropdown-menu">
                    
                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../BasicNLP/LM/LM.html">
                        Language Model
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../Transformer/architecture/introduction.html">
                        Introduction
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../Transformer/architecture/transformer_family.html">
                        Transformer Family
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../TransformerModels/introduction.html">
                        Transformer models
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../Exercise/introduction.html">
                        Downstream Task
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../Exercise/sentiment_analysis.html">
                        감성분석 (Sentiment Analysis)
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../Exercise/Making_Transformers_Efficient_in_Production.html">
                        Making Transformers Efficient in Production
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../Exercise/Training_Transformers_from_Scratch.html">
                        Training Transformers from Scratch
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../LLM/introduction.html">
                        Introduction
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../LLM/distributed_application.html">
                        PyTorch로 분산어플리케이션 개발하기
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../LLM/slurm.html">
                        SLURM
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="introduction.html">
                        Introduction
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="LLaMA.html">
                        Meta가 쏘아올린 작은공 LLaMA
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="Alpaca.html">
                        Hello, Alpaca?
                      </a>
                    </li>
                

                    <li class="nav-item current active">
                      <a class="nav-link nav-internal" href="#">
                        Parameter Efficient Fine-Tuning(PEFT)
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../DevChatGPT/introduction.html">
                        Introduction
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../Appendix/appendix.html">
                        Appendix
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../Appendix/DeepLearningMath/calculus.html">
                        미분과 그래디언트
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../Appendix/DeepLearningMath/MLE.html">
                        MLE (Maximum Likelihood Estimation)
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../Appendix/DeepLearningMath/MAP.html">
                        MAP (Maximum A P Posteriori Estimation)
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../Appendix/DeepLearningMath/naiveBayesClassifier.html">
                        Naive Bayes Classifier
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../Appendix/Entropy/informationEntropy.html">
                        정보와 엔트로피
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../Appendix/Entropy/jointConditionalEntropy.html">
                        Joint Entropy와 Conditional Entropy
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../Appendix/Entropy/crossEntropyKLDivergence.html">
                        Mutual Information, Cross Entropy 그리고 KL Divergence까지
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../Appendix/LinearAlgebra/eigenvectorvalue.html">
                        Eigenvector와 Eigenvalue
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../Appendix/LinearAlgebra/eigen_example.html">
                        Eigenvector와 Eigenvalue를 활용한 PCA 예시
                      </a>
                    </li>
                
                </div>
            </div>
            
    </ul>
</nav>
      </div>
      
      </div>
    

    
    
    <div class="sidebar-header-items__end">
      
      <div class="navbar-end-item">
        <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
</button>
      </div>
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
      </ul>
      </div>
      
    </div>
    
  </div>

  
  <div class="sidebar-start-items sidebar-primary__section">
    <div class="sidebar-start-items__item">
  


<a class="navbar-brand logo" href="../intro.html">

  
  
  
  
  
  
  

  
    <img src="../_static/logo.png" class="logo__image only-light" alt="Logo image">
    <img src="../_static/logo.png" class="logo__image only-dark" alt="Logo image">
  
  
</a>
    </div>
    <div class="sidebar-start-items__item">
<form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false">
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
    </div>
    <div class="sidebar-start-items__item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../intro.html">
                    들어가며
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">1장 SetUp</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../Setup/setup.html">Setup</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../Setup/setup_env.html">패키지 설치 및 환경설정</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../NLP/nlp.html">Natural Language Processing</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">2장 BasicNLP</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../BasicNLP/overview/overview.html">Overview</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../BasicNLP/overview/%ED%95%9C%EA%B8%80%EA%B3%BC%EC%9E%90%EC%97%B0%EC%96%B4%EC%B2%98%EB%A6%AC.html">한국어와 자연어처리</a></li>
<li class="toctree-l2"><a class="reference internal" href="../BasicNLP/overview/%EC%9E%90%EC%97%B0%EC%96%B4%EC%B2%98%EB%A6%AC%EC%9A%A9%EC%96%B4.html">token, sentence, vector spaces, embedding</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../BasicNLP/text_representation/text_representation.html">Text Representation</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../BasicNLP/text_representation/tf-idf.html">TF-IDF</a></li>
<li class="toctree-l2"><a class="reference internal" href="../BasicNLP/text_representation/word2vec.html">Word2Vec &amp; GloVe</a></li>
<li class="toctree-l2"><a class="reference internal" href="../BasicNLP/text_representation/contextual_word_representation.html">Contextual word representation</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../BasicNLP/dl_nlp/dl_nlp.html">Deep Learning for NLP</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../BasicNLP/dl_nlp/mlp.html">MLP(Multi-Layer Perceptron)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../BasicNLP/dl_nlp/cnn.html">CNN</a></li>
<li class="toctree-l2"><a class="reference internal" href="../BasicNLP/dl_nlp/rnn.html">RNN</a></li>
<li class="toctree-l2"><a class="reference internal" href="../BasicNLP/dl_nlp/attention_mechanism.html">Attention mechanism</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../BasicNLP/LM/LM.html">Language Model</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-5"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../BasicNLP/LM/probability.html">Probability Theory</a></li>
<li class="toctree-l2"><a class="reference internal" href="../BasicNLP/LM/disc_gen_model.html">Discriminative VS Generative model</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">3장 Transformer</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../Transformer/architecture/introduction.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Transformer/architecture/transformer_family.html">Transformer Family</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../TransformerModels/introduction.html">Transformer models</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-6"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../TransformerModels/transformers.html">Transformers로 뭘 할 수 있을까요?</a></li>









<li class="toctree-l2"><a class="reference internal" href="../TransformerModels/transformers%EC%82%AC%EC%9A%A9%EB%B2%95.html">Transformer 사용법</a></li>
<li class="toctree-l2"><a class="reference internal" href="../TransformerModels/%EB%8B%A4%EC%96%91%ED%95%9C%EC%96%B8%EC%96%B4%EB%AA%A8%EB%8D%B8.html">언어모델의 다양한 아키텍쳐</a></li>
<li class="toctree-l2"><a class="reference internal" href="../TransformerModels/bias_and_limitations.html">언어모델의 편견 및 한계</a></li>
<li class="toctree-l2"><a class="reference internal" href="../TransformerModels/%EB%A7%BA%EC%9C%BC%EB%A9%B0.html">맺으며</a></li>
<li class="toctree-l2"><a class="reference internal" href="../TransformerModels/%ED%80%B4%EC%A6%88.html">챕터 끝 퀴즈</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">4장 Downstream Task</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../Exercise/introduction.html">Downstream Task</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Exercise/sentiment_analysis.html">감성분석 (Sentiment Analysis)</a></li>









<li class="toctree-l1"><a class="reference internal" href="../Exercise/Making_Transformers_Efficient_in_Production.html">Making Transformers Efficient in Production</a></li>






<li class="toctree-l1"><a class="reference internal" href="../Exercise/Training_Transformers_from_Scratch.html">Training Transformers from Scratch</a></li>

</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">5장 Large Language Models(LLMs)</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../LLM/introduction.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../LLM/distributed_application.html">PyTorch로 분산어플리케이션 개발하기</a></li>
<li class="toctree-l1"><a class="reference internal" href="../LLM/slurm.html">SLURM</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">6장 ChatGPT</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="introduction.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="LLaMA.html">Meta가 쏘아올린 작은공 LLaMA</a></li>
<li class="toctree-l1"><a class="reference internal" href="Alpaca.html">Hello, Alpaca?</a></li>



<li class="toctree-l1 current active"><a class="current reference internal" href="#">Parameter Efficient Fine-Tuning(PEFT)</a></li>

</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">7장 나만의 ChatGPT 만들기</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../DevChatGPT/introduction.html">Introduction</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">부록</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../Appendix/appendix.html">Appendix</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Appendix/DeepLearningMath/calculus.html">미분과 그래디언트</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Appendix/DeepLearningMath/MLE.html">MLE (Maximum Likelihood Estimation)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Appendix/DeepLearningMath/MAP.html">MAP (Maximum A P Posteriori Estimation)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Appendix/DeepLearningMath/naiveBayesClassifier.html">Naive Bayes Classifier</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Appendix/Entropy/informationEntropy.html">정보와 엔트로피</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Appendix/Entropy/jointConditionalEntropy.html">Joint Entropy와 Conditional Entropy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Appendix/Entropy/crossEntropyKLDivergence.html">Mutual Information, Cross Entropy 그리고 KL Divergence까지</a></li>


<li class="toctree-l1"><a class="reference internal" href="../Appendix/LinearAlgebra/eigenvectorvalue.html">Eigenvector와 Eigenvalue</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Appendix/LinearAlgebra/eigen_example.html">Eigenvector와 Eigenvalue를 활용한 PCA 예시</a></li>
</ul>

    </div>
</nav>
    </div>
  </div>
  

  
  <div class="sidebar-end-items sidebar-primary__section">
    <div class="sidebar-end-items__item">
    </div>
  </div>

  
  <div id="rtd-footer-container"></div>

      </div>
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

        <div class="bd-content">
          <div class="bd-article-container">
            
            <div class="bd-header-article">
                



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        <label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" data-toggle="tooltip" data-placement="right" title="Toggle primary sidebar">
            <span class="fa-solid fa-bars"></span>
        </label>
    </div>
    <div class="header-article__right">
<button onclick="toggleFullScreen()"
  class="btn btn-sm"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<div class="dropdown dropdown-repository-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      <li><a href="https://github.com/eagle705/nlp-book" target="_blank"
   class="btn btn-sm dropdown-item"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">repository</span>
</a>
</a>
      
      <li><a href="https://github.com/eagle705/nlp-book/issues/new?title=Issue%20on%20page%20%2FChatGPT/PEFT.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm dropdown-item"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">open issue</span>
</a>
</a>
      
  </ul>
</div>



<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      <li><a href="../_sources/ChatGPT/PEFT.md" target="_blank"
   class="btn btn-sm dropdown-item"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</a>
      
      <li>
<button onclick="printPdf(this)"
  class="btn btn-sm dropdown-item"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</a>
      
  </ul>
</div>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary" data-toggle="tooltip" data-placement="left" title="Toggle secondary sidebar">
            <span class="fa-solid fa-list"></span>
        </label>
    </div>
</div>
            </div>
            
            

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Parameter Efficient Fine-Tuning(PEFT)</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   Parameter Efficient Fine-Tuning(PEFT)
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#llm-peft">
     LLM의 발전과 PEFT의 필요성
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#peft">
     PEFT 기법들
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#lora">
     LoRA
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#alpaca-lora">
       Alpaca-LoRA
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#ia3">
     IA3
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id1">
   마치며
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id2">
     참고자료
    </a>
   </li>
  </ul>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>

            <article class="bd-article" role="main">
              
  <section class="tex2jax_ignore mathjax_ignore" id="parameter-efficient-fine-tuning-peft">
<h1>Parameter Efficient Fine-Tuning(PEFT)<a class="headerlink" href="#parameter-efficient-fine-tuning-peft" title="Permalink to this heading">#</a></h1>
<p>안녕하세요🙂 오늘은 <code class="docutils literal notranslate"><span class="pre">Parameter</span> <span class="pre">Efficient</span> <span class="pre">Fine-Tuning(PEFT)</span></code>이라고 불리우는 모델 튜닝 방법에 대해서 알아보도록 하겠습니다.</p>
<p>PEFT에 대해서 짧게 설명드리면 모델의 모든 파라미터를 튜닝하는 것이 아닌 <strong>일부 파라미터만을 튜닝</strong>함으로써 모델의 성능을 적은 자원으로도 높게 유지하는 방법론입니다. PEFT 기법중에서 가장 많이 알려진 것은 LoRA라는 기법인데요. 오늘은 LoRA에 대해서 간단하게 배우고 더 나아가 IA3라는 방법론에 대해서도 짧게 리뷰해보도록 하겠습니다.</p>
<section id="llm-peft">
<h2>LLM의 발전과 PEFT의 필요성<a class="headerlink" href="#llm-peft" title="Permalink to this heading">#</a></h2>
<p>최근 GPT-3(175B)와 같은 매우 큰 언어모델(LLM)이 등장함에 따라 다양한 문제를 쉽게 언어모델에 해결할 수 있게 되었습니다. 풀고자 하는 문제에 대한 몇가지 예시만 few-shot으로 모델에 미리 입력을 해주면 in-context learning(ICL)에 의해 모델을 따로 튜닝할 필요 없이 쉽게 문제를 풀 수 있게 된 것입니다.</p>
<p><img alt="image" src="https://user-images.githubusercontent.com/7252598/232743915-d6b309c5-6029-4a30-b9f2-3062206cac44.png" /></p>
<p>그러나 이러한 ICL은 매번 미리 예제를 입력해주어야하기 때문에 계산비용, 메모리비용, 저장비용등이 발생하게 된다는 단점이 있습니다. 또한 어떤 연구에서는 incorrect labels을 예제로 넣어주더라도 문제를 잘 해결하기도 하더라 라는 내용도 있어서 ICL의 결과를 온전히 신뢰하기 어렵다 라는 의견도 있습니다.</p>
<p>오늘 다루게 되는 <code class="docutils literal notranslate"><span class="pre">PEFT(Parameter</span> <span class="pre">Efficient</span> <span class="pre">Fine-Tuning)</span></code>은 이러한 단점을 보완하는 대안적인 패러다임중 하나이고 적은양 파라미터(예를 들면 0.01%)를 학습함으로써 빠른 시간 내에 새로운 문제를 거의 비슷한 성능으로 풀 수 있게 하자는게 주된 목표입니다. 언어모델처럼 매우 많은 수의 파라미터를 쓰는 모델이 사실은 적은 수의 파라미터를 튜닝해도 비슷한 성능을 낼 수 있다는 선행연구들이 있었고 이러한 연구를 기반으로 현재 PEFT를 위한 다양한 방법론들이 연구되고 있습니다. 그러한 방법론중에서 가장 유명한 것중 하나가 LoRA이고, 최근에는 LoRA를 개선한 방법론들도 많이 나오고 있는 상황입니다. 이번에는 LoRA에 대해서 간단하게 리뷰하고 IA3라는 더 개선된 방법에 대해서도 살펴보려합니다. 현시점 기준으로 LoRA는 <a class="reference external" href="https://github.com/huggingface/peft">Huggingface에서 공개한 PEFT 라이브러리</a>에서 구현이 되어있고 IA3의 경우 <a class="reference external" href="https://github.com/NVIDIA/NeMo/commit/cb2793c0c7bb352e1dfd8c349a96efc1dd260179">NVIDIA NeMo</a>에 구현이 되어있습니다.</p>
</section>
<section id="peft">
<h2>PEFT 기법들<a class="headerlink" href="#peft" title="Permalink to this heading">#</a></h2>
<p>초기에 PEFT을 위해 제안되었던 방법은 어댑터(<code class="docutils literal notranslate"><span class="pre">adapters</span></code>)를 사용하는 것입니다. 여기서 말하는 <code class="docutils literal notranslate"><span class="pre">adapater</span></code>란 기존에 이미 학습이 완료된 모델(pre-trained model)의 사이사이에 <strong>학습 가능한 작은 feed-forward networks를 삽입하는 구조</strong>를 말합니다. 이때 pre-trained model의 weights는 고정해놓고 학습 가능한 작은 feed-forward networks만 아키텍쳐 중간 중간마다 추가함으로써 적은 수의 파라미터로 모델을 튜닝하는 기법입니다.이러한 어댑터기반의 방법론 외에도 <code class="docutils literal notranslate"><span class="pre">LoRA</span></code>, <code class="docutils literal notranslate"><span class="pre">prompt</span> <span class="pre">tuning</span></code>, <code class="docutils literal notranslate"><span class="pre">prefix</span> <span class="pre">tuning</span></code>등 다양한 방법론이 제안되었습니다.여러 방법론이 있지만 Stable diffusion이나 LLaMA, <a class="reference external" href="https://devocean.sk.com/search/techBoardDetail.do?ID=164659">Alpaca</a>에서도 많이 적용되는 Microsoft에서 공개한 <code class="docutils literal notranslate"><span class="pre">LoRA</span></code>라는 방법론이 현재로서는 제일 유명한 것 같습니다.</p>
</section>
<section id="lora">
<h2>LoRA<a class="headerlink" href="#lora" title="Permalink to this heading">#</a></h2>
<p>LoRA(<strong>Lo</strong>w-<strong>R</strong>ank <strong>A</strong>daptation)의 개념을 간단하게 설명하자면, 고정된 weights를 갖는 pretrained model에 학습이 가능한 rank decomposition 행렬을 삽입한것으로 중간중간 학습이 가능한 파라미터를 삽입했다는 점에서는 어댑터와 비슷하지만 구조적으로 조금 다르다고 할 수 있습니다.
적은 양의 파라미터로 모델을 튜닝하는 방법론이기 때문에 적은수의 GPU로 빠르게 튜닝할 수 있다는 장점이 있습니다. LoRA에서 나온 rank decomposition이라는 말이 처음에는 어렵게 느껴졌었는데요. 아래 보이는 그림에서 처럼 행렬의 차원을 <code class="docutils literal notranslate"><span class="pre">r</span></code> 만큼 줄이는 행렬과 다시 원래 크기로 키워주는 행렬의 곱으로 나타내는 것을 의미합니다.</p>
<p><img alt="LoRA" src="https://user-images.githubusercontent.com/7252598/230259439-fe58295d-9879-41c8-9454-0ecbe27cacde.png" /></p>
<p>위 그림처럼 레이어 중간중간마다 존재하는 hidden states <code class="docutils literal notranslate"><span class="pre">h</span></code>에 값을 더해줄수 있는 파라미터를 추가해줘서 모델의 출력 값을 원하는 타겟 레이블에 맞게 튜닝하는 것이 LoRA의 핵심 개념이라고 할 수 있습니다. 코드상으로는 아래와 같이 구현할 수 있는데요. 기존에 모델에서 사용하던 <code class="docutils literal notranslate"><span class="pre">Linear</span> <span class="pre">Layer</span></code>를 LoRA의 로직이 적용된 커스텀 클래스로 교체해주면 적용할 수 있습니다.
<code class="docutils literal notranslate"><span class="pre">if</span> <span class="pre">self.r</span> <span class="pre">&gt;</span> <span class="pre">0:</span></code> 라는 if 문이 추가된 부분이 LoRA가 적용된 부분입니다.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Linear</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">,</span> <span class="n">LoRALayer</span><span class="p">):</span>
    <span class="c1"># LoRA implemented in a dense layer</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> 
        <span class="n">in_features</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> 
        <span class="n">out_features</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> 
        <span class="n">r</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> 
        <span class="n">lora_alpha</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> 
        <span class="n">lora_dropout</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.</span><span class="p">,</span>
        <span class="n">fan_in_fan_out</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="c1"># Set this to True if the layer to replace stores weight like (fan_in, fan_out)</span>
        <span class="n">merge_weights</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span>
    <span class="p">):</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="n">LoRALayer</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">r</span><span class="o">=</span><span class="n">r</span><span class="p">,</span> <span class="n">lora_alpha</span><span class="o">=</span><span class="n">lora_alpha</span><span class="p">,</span> <span class="n">lora_dropout</span><span class="o">=</span><span class="n">lora_dropout</span><span class="p">,</span>
                           <span class="n">merge_weights</span><span class="o">=</span><span class="n">merge_weights</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">fan_in_fan_out</span> <span class="o">=</span> <span class="n">fan_in_fan_out</span>
        <span class="c1"># Actual trainable parameters</span>
        <span class="k">if</span> <span class="n">r</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">lora_A</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">new_zeros</span><span class="p">((</span><span class="n">r</span><span class="p">,</span> <span class="n">in_features</span><span class="p">)))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">lora_B</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">new_zeros</span><span class="p">((</span><span class="n">out_features</span><span class="p">,</span> <span class="n">r</span><span class="p">)))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">scaling</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lora_alpha</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">r</span>
            <span class="c1"># Freezing the pre-trained weight matrix</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reset_parameters</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">fan_in_fan_out</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">T</span>

    <span class="k">def</span> <span class="nf">reset_parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="o">.</span><span class="n">reset_parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;lora_A&#39;</span><span class="p">):</span>
            <span class="c1"># initialize A the same way as the default for nn.Linear and B to zero</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">kaiming_uniform_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lora_A</span><span class="p">,</span> <span class="n">a</span><span class="o">=</span><span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">5</span><span class="p">))</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">zeros_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lora_B</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mode</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">):</span>
        <span class="k">def</span> <span class="nf">T</span><span class="p">(</span><span class="n">w</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">w</span><span class="o">.</span><span class="n">T</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">fan_in_fan_out</span> <span class="k">else</span> <span class="n">w</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mode</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">merge_weights</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">merged</span><span class="p">:</span>
            <span class="c1"># Make sure that the weights are not merged</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">r</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span> <span class="o">-=</span> <span class="n">T</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lora_B</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">lora_A</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">scaling</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">merged</span> <span class="o">=</span> <span class="kc">False</span>
    
    <span class="k">def</span> <span class="nf">eval</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">def</span> <span class="nf">T</span><span class="p">(</span><span class="n">w</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">w</span><span class="o">.</span><span class="n">T</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">fan_in_fan_out</span> <span class="k">else</span> <span class="n">w</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="o">.</span><span class="n">eval</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">merge_weights</span> <span class="ow">and</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">merged</span><span class="p">:</span>
            <span class="c1"># Merge the weights and mark it</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">r</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span> <span class="o">+=</span> <span class="n">T</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lora_B</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">lora_A</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">scaling</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">merged</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
        <span class="k">def</span> <span class="nf">T</span><span class="p">(</span><span class="n">w</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">w</span><span class="o">.</span><span class="n">T</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">fan_in_fan_out</span> <span class="k">else</span> <span class="n">w</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">r</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">merged</span><span class="p">:</span>
            <span class="n">result</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">T</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weight</span><span class="p">),</span> <span class="n">bias</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">bias</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">r</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">result</span> <span class="o">+=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lora_dropout</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">lora_A</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">lora_B</span><span class="o">.</span><span class="n">T</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">scaling</span>
            <span class="k">return</span> <span class="n">result</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">T</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weight</span><span class="p">),</span> <span class="n">bias</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">bias</span><span class="p">)</span>
</pre></div>
</div>
<p>위 코드에서 주목할 부분은 <code class="docutils literal notranslate"><span class="pre">eval</span></code> 함수쪽인데요.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">eval</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">T</span><span class="p">(</span><span class="n">w</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">w</span><span class="o">.</span><span class="n">T</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">fan_in_fan_out</span> <span class="k">else</span> <span class="n">w</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="o">.</span><span class="n">eval</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">merge_weights</span> <span class="ow">and</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">merged</span><span class="p">:</span>
        <span class="c1"># Merge the weights and mark it</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">r</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span> <span class="o">+=</span> <span class="n">T</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lora_B</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">lora_A</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">scaling</span> <span class="c1"># 행렬을 합치는 부분</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">merged</span> <span class="o">=</span> <span class="kc">True</span>
</pre></div>
</div>
<p>LoRA가 행렬 연산을 기반으로 하기 때문에 기존 행렬 W_0를 LoRA에서 사용하는 A, B 행렬을 기반으로 다음과 같이 재구성할 수 있습니다.</p>
<blockquote>
<div><p>W = W_0 + BA</p>
</div></blockquote>
<p>이렇게 함으로써 얻을 수 있는 이점은 새롭게 학습한 파라미터를 기존에 학습된 pretrained model에 합쳐줌으로써 추가적인 연산이 필요하지 않게 되어 속도도 그대로 유지하면서 아키텍쳐의 변경도 필요없어지게 됩니다.</p>
<section id="alpaca-lora">
<h3>Alpaca-LoRA<a class="headerlink" href="#alpaca-lora" title="Permalink to this heading">#</a></h3>
<p>최근에 유행하는 LLaMA의 변형인 Alpaca에도 LoRA가 적용된 오픈소스 프로젝트들이 공개되고 있는데요. <a class="reference external" href="https://github.com/huggingface/peft">Huggingface에서 공개한 PEFT 라이브러리</a>를 이용하면 아래와 같이 적용도 매우 간단하게 할 수 있습니다.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">peft</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">LoraConfig</span><span class="p">,</span>
    <span class="n">get_peft_model</span><span class="p">,</span>
    <span class="n">get_peft_model_state_dict</span><span class="p">,</span>
    <span class="n">prepare_model_for_int8_training</span><span class="p">,</span>
    <span class="n">set_peft_model_state_dict</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">LlamaForCausalLM</span><span class="p">,</span> <span class="n">LlamaTokenizer</span>

<span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="o">...</span><span class="p">):</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">prepare_model_for_int8_training</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
    <span class="n">config</span> <span class="o">=</span> <span class="n">LoraConfig</span><span class="p">(</span>
        <span class="n">r</span><span class="o">=</span><span class="n">lora_r</span><span class="p">,</span>
        <span class="n">lora_alpha</span><span class="o">=</span><span class="n">lora_alpha</span><span class="p">,</span>
        <span class="n">target_modules</span><span class="o">=</span><span class="n">lora_target_modules</span><span class="p">,</span>
        <span class="n">lora_dropout</span><span class="o">=</span><span class="n">lora_dropout</span><span class="p">,</span>
        <span class="n">bias</span><span class="o">=</span><span class="s2">&quot;none&quot;</span><span class="p">,</span>
        <span class="n">task_type</span><span class="o">=</span><span class="s2">&quot;CAUSAL_LM&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">get_peft_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">config</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<section id="ia3">
<h2>IA3<a class="headerlink" href="#ia3" title="Permalink to this heading">#</a></h2>
<p>IA3(<strong>I</strong>nfused <strong>A</strong>dapter by <strong>I</strong>nhibiting and <strong>A</strong>mplifying <strong>I</strong>nner <strong>A</strong>ctivations)의 개념을 간단하게 설명하자면, LoRA와 비슷한 방법으로 적은 파라미터만을 추가해서 모델을 튜닝할 수 있는 방법론 입니다. 이름에도 나와있듯이 뉴럴네트워크의 Inner Activation을 줄이기도하고 늘리기도하는 어댑터를 중간에 삽입하는 방법론인데요. LoRA의 경우에는 hidden state에 새로운 값을 더해주는 기법이었다면 IA3의 경우에는 <code class="docutils literal notranslate"><span class="pre">Self-Attention,</span> <span class="pre">Cross-Attention에서의</span> <span class="pre">Key,</span> <span class="pre">Value</span> <span class="pre">값을</span> <span class="pre">rescale해주는</span> <span class="pre">벡터와</span> <span class="pre">position-wise</span> <span class="pre">feed-forward</span> <span class="pre">network의</span> <span class="pre">값에</span> <span class="pre">rescale을</span> <span class="pre">해주는</span> <span class="pre">벡터를</span> <span class="pre">추가해서</span> <span class="pre">모델을</span> <span class="pre">튜닝</span></code>해주는 기법입니다.</p>
<p><img alt="IA3" src="https://user-images.githubusercontent.com/7252598/230011306-0e6184ac-af46-4920-b483-03e2481d0457.png" /></p>
<p>IA3(T-Few라고도 부름)는 기존에 공개된 LoRA보다 적은 파라미터를 사용하면서 높은 성능을 내는 것으로 알려져있으며, GPT-3를 in-context learning 했을때 보다도 성능이 좋다 라고 주장하고 있습니다. 학습시간도 매우 짧은데요. A100 GPU 하나로 30분만에 튜닝할 수 있었다고 합니다.</p>
<table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>PEFT 성능비교 그래프</p></th>
<th class="head"><p>ICL 성능비교표</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><img alt="ia3_performance" src="https://user-images.githubusercontent.com/7252598/230011771-6be13446-6fd8-4a6d-a558-219cdd975eee.png" /></p></td>
<td><p><img alt="image" src="https://user-images.githubusercontent.com/7252598/232739247-1ee59fc6-7141-49ca-9500-655d03029580.png" /></p></td>
</tr>
</tbody>
</table>
<p>IA3도 LoRA와 마찬가지로 Linear Layer를 커스텀 구현체로 변경함으로써 구현이 가능하며, LoRA Layer에 대한 configuration을 수정해서 구현할 수 있습니다. 다음은 IA3에 대한 구현체입니다.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">configs/ia3.json</span></code></p></li>
</ul>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
<span class="w">    </span><span class="nt">&quot;lora_scaling_rank&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;lora_rank&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;lora_init_scale&quot;</span><span class="p">:</span><span class="w"> </span><span class="mf">0.0</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;lora_modules&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;.*SelfAttention|.*EncDecAttention|.*DenseReluDense&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;lora_layers&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;k|v|wi_1.*&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;trainable_param_names&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;.*lora_b.*&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;model_modifier&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;lora&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;lr&quot;</span><span class="p">:</span><span class="w"> </span><span class="mf">3e-3</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;num_steps&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">1000</span>
<span class="p">}</span>
</pre></div>
</div>
<ul class="simple">
<li><p><a class="reference external" href="https://github.com/r-three/t-few/blob/4e581fa0b8f53e36da252a15bd581d365d4dd333/src/models/lora.py#L7">LoRA기반 IA3 구현체</a></p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>
<span class="k">def</span> <span class="nf">modify_with_lora</span><span class="p">(</span><span class="n">transformer</span><span class="p">,</span> <span class="n">config</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">m_name</span><span class="p">,</span> <span class="n">module</span> <span class="ow">in</span> <span class="nb">dict</span><span class="p">(</span><span class="n">transformer</span><span class="o">.</span><span class="n">named_modules</span><span class="p">())</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="k">if</span> <span class="n">re</span><span class="o">.</span><span class="n">fullmatch</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">lora_modules</span><span class="p">,</span> <span class="n">m_name</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">c_name</span><span class="p">,</span> <span class="n">layer</span> <span class="ow">in</span> <span class="nb">dict</span><span class="p">(</span><span class="n">module</span><span class="o">.</span><span class="n">named_children</span><span class="p">())</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="k">if</span> <span class="n">re</span><span class="o">.</span><span class="n">fullmatch</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">lora_layers</span><span class="p">,</span> <span class="n">c_name</span><span class="p">):</span>
                    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span>
                        <span class="n">layer</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span>
                    <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;LoRA can only be applied to torch.nn.Linear, but </span><span class="si">{</span><span class="n">layer</span><span class="si">}</span><span class="s2"> is </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">layer</span><span class="p">)</span><span class="si">}</span><span class="s2">.&quot;</span>
                    <span class="nb">setattr</span><span class="p">(</span>
                        <span class="n">module</span><span class="p">,</span>
                        <span class="n">c_name</span><span class="p">,</span>
                        <span class="n">LoRALinear</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">lora_rank</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">lora_scaling_rank</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">lora_init_scale</span><span class="p">),</span>
                    <span class="p">)</span>
    <span class="k">return</span> <span class="n">transformer</span>

<span class="k">class</span> <span class="nc">LoRALinear</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">linear_layer</span><span class="p">,</span> <span class="n">rank</span><span class="p">,</span> <span class="n">scaling_rank</span><span class="p">,</span> <span class="n">init_scale</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">in_features</span> <span class="o">=</span> <span class="n">linear_layer</span><span class="o">.</span><span class="n">in_features</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out_features</span> <span class="o">=</span> <span class="n">linear_layer</span><span class="o">.</span><span class="n">out_features</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rank</span> <span class="o">=</span> <span class="n">rank</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scaling_rank</span> <span class="o">=</span> <span class="n">scaling_rank</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weight</span> <span class="o">=</span> <span class="n">linear_layer</span><span class="o">.</span><span class="n">weight</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bias</span> <span class="o">=</span> <span class="n">linear_layer</span><span class="o">.</span><span class="n">bias</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">rank</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">lora_a</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">rank</span><span class="p">,</span> <span class="n">linear_layer</span><span class="o">.</span><span class="n">in_features</span><span class="p">)</span> <span class="o">*</span> <span class="n">init_scale</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">init_scale</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">lora_b</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">linear_layer</span><span class="o">.</span><span class="n">out_features</span><span class="p">,</span> <span class="n">rank</span><span class="p">)</span> <span class="o">*</span> <span class="n">init_scale</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">lora_b</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">linear_layer</span><span class="o">.</span><span class="n">out_features</span><span class="p">,</span> <span class="n">rank</span><span class="p">))</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">scaling_rank</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">multi_lora_a</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">scaling_rank</span><span class="p">,</span> <span class="n">linear_layer</span><span class="o">.</span><span class="n">in_features</span><span class="p">)</span>
                <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">scaling_rank</span><span class="p">,</span> <span class="n">linear_layer</span><span class="o">.</span><span class="n">in_features</span><span class="p">)</span> <span class="o">*</span> <span class="n">init_scale</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="n">init_scale</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">multi_lora_b</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span>
                    <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">linear_layer</span><span class="o">.</span><span class="n">out_features</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">scaling_rank</span><span class="p">)</span>
                    <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">linear_layer</span><span class="o">.</span><span class="n">out_features</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">scaling_rank</span><span class="p">)</span> <span class="o">*</span> <span class="n">init_scale</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">multi_lora_b</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">linear_layer</span><span class="o">.</span><span class="n">out_features</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">scaling_rank</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">scaling_rank</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">rank</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="c1"># parsimonious implementation for ia3 and lora scaling</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">multi_lora_a</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">:</span>
                <span class="c1"># 이 부분에서 IA3의 연산이 이루어집니다.</span>
                <span class="n">hidden</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">linear</span><span class="p">((</span><span class="nb">input</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">multi_lora_a</span><span class="o">.</span><span class="n">flatten</span><span class="p">()),</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">hidden</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">multi_lora_b</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">:</span>
                <span class="n">hidden</span> <span class="o">=</span> <span class="n">hidden</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">multi_lora_b</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
            <span class="k">return</span> <span class="n">hidden</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># general implementation for lora (adding and scaling)</span>
            <span class="n">weight</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">scaling_rank</span><span class="p">:</span>
                <span class="n">weight</span> <span class="o">=</span> <span class="n">weight</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">multi_lora_b</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">multi_lora_a</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">scaling_rank</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">rank</span><span class="p">:</span>
                <span class="n">weight</span> <span class="o">=</span> <span class="n">weight</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lora_b</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">lora_a</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">rank</span>
            <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span><span class="p">)</span>
</pre></div>
</div>
<p>전반적으로 LoRA의 구현안에서 변형된 형태임을 확인할 수 있습니다. 아마 언젠가 Huggingface의 PEFT 라이브러리 안에도 들어갈 날이 오지 않을까 싶네요.</p>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="id1">
<h1>마치며<a class="headerlink" href="#id1" title="Permalink to this heading">#</a></h1>
<p>최근 몇년간 <a class="reference external" href="https://arxiv.org/abs/2001.08361">Scaling laws</a>에 따라 언어모델의 크기가 점점 커지고 있는 시대에 살고 있는 것 같습니다. 이러한 상황 속에서 인프라가 없는 개인이나 기업에게는 적은 자원으로도 모델을 빠르게 튜닝할 수 있는 PEFT(Parameter Efficient Fine-Tuning)가 훌륭한 대안이 될 수 있을 것 같습니다. 오늘은 PEFT에서 가장 유명한 방법론중 하나인 LoRA와 IA3라는 개선된 방법론을 다루어봤는데요. LLaMA, <a class="reference external" href="https://devocean.sk.com/search/techBoardDetail.do?ID=164659">Alpaca</a>의 등장과 함께 Quantization과 PEFT를 활용해서 빅모델을 개인이 쉽게 사용할 수 있게 하는 시대가 점점 오고 있는 것 같습니다. 적은 비용으로도 높은 성능을 갖는 나만의 튜닝된 모델을 갖고 싶다면 오늘 소개해드린 PEFT에 대해서 고려해보시는 건 어떨까요?🙂</p>
<section id="id2">
<h2>참고자료<a class="headerlink" href="#id2" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p><a class="reference external" href="https://arxiv.org/abs/2005.14165">Language Models are Few-Shot Learners</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/2012.13255">Intrinsic Dimensionality Explains the Effectiveness of Language Model Fine-Tuning</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/2106.09685">LoRA: Low-Rank Adaptation of Large Language Models</a></p></li>
<li><p><a class="reference external" href="https://github.com/microsoft/LoRA">LoRA Github</a></p></li>
<li><p><a class="reference external" href="https://github.com/tloen/alpaca-lora/blob/8bb8579e403dc78e37fe81ffbb253c413007323f/finetune.py#L176">Alpaca-LoRA Github</a></p></li>
<li><p><a class="reference external" href="https://github.com/huggingface/peft">PEFT Library Huggingface</a></p></li>
<li><p><a class="reference external" href="https://github.com/NVIDIA/NeMo/commit/cb2793c0c7bb352e1dfd8c349a96efc1dd260179">IA3 NVIDIA NeMo</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/2205.05638">Few-Shot Parameter-Efficient Fine-Tuning is Better and Cheaper than In-Context Learning</a></p></li>
<li><p><a class="reference external" href="https://github.com/r-three/t-few">IA3(T-Few) Github</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/2001.08361">Scaling Laws for Neural Language Models</a></p></li>
<li><p><a class="reference external" href="https://devocean.sk.com/search/techBoardDetail.do?ID=164659">ChatGPT, LLaMA 그리고 이젠 Alpaca?</a></p></li>
</ul>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./ChatGPT"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

            </article>
            

            
            
            <footer class="bd-footer-article">
                <!-- Previous / next buttons -->
<div class='prev-next-area'>
  <a class='left-prev' id="prev-link" href="Alpaca.html" title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
          <p class="prev-next-subtitle">previous</p>
          <p class="prev-next-title">Hello, Alpaca?</p>
      </div>
  </a>
  <a class='right-next' id="next-link" href="../DevChatGPT/introduction.html" title="next page">
  <div class="prev-next-info">
      <p class="prev-next-subtitle">next</p>
      <p class="prev-next-title">Introduction</p>
  </div>
  <i class="fa-solid fa-angle-right"></i>
  </a>
</div>
            </footer>
            
          </div>
          
          
          
            <div class="bd-sidebar-secondary bd-toc">
              
<div class="toc-item">
  
<div class="tocsection onthispage">
    <i class="fa-solid fa-list"></i> On this page
</div>
<nav id="bd-toc-nav" class="page-toc">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   Parameter Efficient Fine-Tuning(PEFT)
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#llm-peft">
     LLM의 발전과 PEFT의 필요성
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#peft">
     PEFT 기법들
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#lora">
     LoRA
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#alpaca-lora">
       Alpaca-LoRA
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#ia3">
     IA3
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id1">
   마치며
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id2">
     참고자료
    </a>
   </li>
  </ul>
 </li>
</ul>

</nav>
</div>

            </div>
          
          
        </div>
        <footer class="bd-footer-content">
          <div class="bd-footer-content__inner">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By JSYoon
</p>

  </div>
  
  <div class="footer-item">
    
<p class="copyright">

    &copy; Copyright 2022.<br>

</p>

  </div>
  
  <div class="footer-item">
    <p class="last-updated">
Last updated on None.<br>
</p>
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </div>
        </footer>
        

      </main>
    </div>
  </div>

  
    
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=796348d33e8b1d947c94"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=796348d33e8b1d947c94"></script>

  </body>
</html>